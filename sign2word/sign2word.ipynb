{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset extracted successfully to 'dataset' folder\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = 'wlasl-processed.zip'\n",
        "\n",
        "os.makedirs('dataset', exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')\n",
        "    \n",
        "print(\"Dataset extracted successfully to 'dataset' folder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocess WLASL dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import audio\n",
        "import pickle\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset path exists: True\n",
            "Metadata file exists: True\n"
          ]
        }
      ],
      "source": [
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=True, \n",
        "                      max_num_hands=2, \n",
        "                      min_detection_confidence=0.5)\n",
        "\n",
        "\n",
        "DATASET_PATH = 'dataset' \n",
        "OUTPUT_PATH = 'data\\\\processed_data'   \n",
        "METADATA_PATH = os.path.join('dataset', 'WLASL_v0.3.json')\n",
        "\n",
        "\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "\n",
        "print(f\"Dataset path exists: {os.path.exists(DATASET_PATH)}\")\n",
        "print(f\"Metadata file exists: {os.path.exists(METADATA_PATH)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_landmarks(frame):\n",
        "\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    \n",
        "\n",
        "    results = hands.process(rgb_frame)\n",
        "    \n",
        "    landmarks = []\n",
        "    \n",
        "    # check if hands are detected\n",
        "    if results.multi_hand_landmarks:\n",
        "        # For each hand found\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            # Extract each landmark\n",
        "            for lm in hand_landmarks.landmark:\n",
        "                landmarks.extend([lm.x, lm.y, lm.z])\n",
        "    \n",
        "\n",
        "    while len(landmarks) < 21 * 3 * 2:  # Max 2 hands\n",
        "        landmarks.append(0.0)\n",
        "    \n",
        "    return landmarks[:21 * 3 * 2]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "VIDEO_DIR = 'dataset/videos'\n",
        "METADATA_PATH = 'dataset/WLASL_v0.3.json'\n",
        "FILTERED_METADATA_PATH = 'data/filtered_wlasl_metadata.json'  \n",
        "\n",
        "\n",
        "with open(METADATA_PATH, 'r') as f:\n",
        "    full_metadata = json.load(f)\n",
        "\n",
        "available_videos = set(os.listdir(VIDEO_DIR))\n",
        "\n",
        "filtered_metadata = []\n",
        "\n",
        "for entry in full_metadata:\n",
        "    valid_instances = []\n",
        "    for instance in entry['instances']:\n",
        "        video_file = f\"{instance['video_id']}.mp4\"\n",
        "        if video_file in available_videos:\n",
        "            valid_instances.append(instance)\n",
        "\n",
        "    # only keep entries with at least one valid video\n",
        "    if valid_instances:\n",
        "        filtered_entry = dict(entry)\n",
        "        filtered_entry['instances'] = valid_instances\n",
        "        filtered_metadata.append(filtered_entry)\n",
        "\n",
        "\n",
        "# save filtered metadata\n",
        "os.makedirs(os.path.dirname(FILTERED_METADATA_PATH), exist_ok=True)\n",
        "with open(FILTERED_METADATA_PATH, 'w') as f:\n",
        "    json.dump(filtered_metadata, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_wlasl_dataset():\n",
        "\n",
        "    with open(FILTERED_METADATA_PATH, 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    processed_data = {\n",
        "        'data': [],\n",
        "        'labels': [],\n",
        "        'label_map': {}\n",
        "    }\n",
        "    \n",
        "    total_videos = 0\n",
        "    videos_found = 0\n",
        "    videos_processed = 0\n",
        "    videos_with_landmarks = 0\n",
        "    \n",
        "\n",
        "    for i, entry in enumerate(metadata):\n",
        "        gloss = entry['gloss']  # sign/word\n",
        "        instances = entry['instances']\n",
        "        \n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            print(f\"Progress: {i}/{len(metadata)} classes ({i/len(metadata)*100:.1f}%)\")\n",
        "        \n",
        "        # add to label map\n",
        "        if gloss not in processed_data['label_map']:\n",
        "            processed_data['label_map'][gloss] = len(processed_data['label_map'])\n",
        "        \n",
        "        label_id = processed_data['label_map'][gloss]\n",
        "        \n",
        "        # process each video instance of this sign\n",
        "        for instance in instances:\n",
        "            total_videos += 1\n",
        "            video_id = instance['video_id']\n",
        "            video_path = os.path.join(DATASET_PATH, 'videos', f'{video_id}.mp4')\n",
        "            \n",
        "            if not os.path.exists(video_path):\n",
        "                continue\n",
        "            \n",
        "            videos_found += 1\n",
        "            \n",
        "            # reead video\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            frames_landmarks = []\n",
        "            frame_count = 0\n",
        "            \n",
        "            # process each frame\n",
        "            while cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                \n",
        "                frame_count += 1\n",
        "                try:\n",
        "                    landmarks = extract_landmarks(frame)\n",
        "                    if landmarks is not None:\n",
        "                        landmarks = normalize_landmarks(landmarks)\n",
        "                        frames_landmarks.append(landmarks)\n",
        "                except Exception as e:\n",
        "                    pass  \n",
        "            \n",
        "            cap.release()\n",
        "            \n",
        "\n",
        "            if not frames_landmarks:\n",
        "                continue\n",
        "            \n",
        "            videos_with_landmarks += 1\n",
        "            \n",
        "\n",
        "            if len(instances) < 10:  # only augment for classes with few examples\n",
        "                augmented_sequences = augment_sequence(frames_landmarks)\n",
        "            else:\n",
        "                augmented_sequences = [frames_landmarks]\n",
        "\n",
        "            for sequence in augmented_sequences:\n",
        "                max_seq_length = 30  \n",
        "                \n",
        "                if len(sequence) > max_seq_length:\n",
        "                    sequence = sequence[:max_seq_length]\n",
        "\n",
        "                elif len(sequence) < max_seq_length:\n",
        "                    if len(sequence) > 0:\n",
        "                        last_frame = sequence[-1]\n",
        "                        padding = [last_frame.copy() for _ in range(max_seq_length - len(sequence))]\n",
        "                        sequence.extend(padding)\n",
        "                    else:\n",
        "                        continue  \n",
        "                \n",
        "                processed_data['data'].append(sequence)\n",
        "                processed_data['labels'].append(label_id)\n",
        "                videos_processed += 1\n",
        "                \n",
        "                # sve intermediate results to prevent data loss\n",
        "                if videos_processed % 5000 == 0:\n",
        "                    print(f\"Progress: Processed {videos_processed} videos so far\")\n",
        "                    temp_save_path = os.path.join(OUTPUT_PATH, f'processed_wlasl_intermediate_{videos_processed}.pickle')\n",
        "                    with open(temp_save_path, 'wb') as f:\n",
        "                        pickle.dump(processed_data, f)\n",
        "    \n",
        "\n",
        "    X = np.array(processed_data['data']) if processed_data['data'] else np.array([])\n",
        "    y = np.array(processed_data['labels']) if processed_data['labels'] else np.array([])\n",
        "    \n",
        "\n",
        "    try:\n",
        "        with open(os.path.join(OUTPUT_PATH, 'processed_wlasl_full.pickle'), 'wb') as f:\n",
        "            pickle.dump(processed_data, f)\n",
        "        \n",
        "\n",
        "        with open(os.path.join(OUTPUT_PATH, 'label_map_full.json'), 'w') as f:\n",
        "            json.dump(processed_data['label_map'], f, indent=4)\n",
        "            \n",
        "        print(\"Successfully saved processed data and label map\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving data: {e}\")\n",
        "        try:\n",
        "            print(\"save data chunks\")\n",
        "            with open(os.path.join(OUTPUT_PATH, 'label_map_full.json'), 'w') as f:\n",
        "                json.dump(processed_data['label_map'], f, indent=4)\n",
        "                \n",
        "            chunk_size = 5000\n",
        "            for i in range(0, len(processed_data['data']), chunk_size):\n",
        "                chunk_data = {\n",
        "                    'data': processed_data['data'][i:i+chunk_size],\n",
        "                    'labels': processed_data['labels'][i:i+chunk_size],\n",
        "                    'label_map': processed_data['label_map']\n",
        "                }\n",
        "                with open(os.path.join(OUTPUT_PATH, f'processed_wlasl_chunk_{i//chunk_size}.pickle'), 'wb') as f:\n",
        "                    pickle.dump(chunk_data, f)\n",
        "            print(f\"Successfully saved data in {math.ceil(len(processed_data['data'])/chunk_size)} chunks\")\n",
        "        except Exception as e2:\n",
        "            print(f\"Error saving chunked data: {e2}\")\n",
        "    \n",
        "    return processed_data, X, y\n",
        "\n",
        "\n",
        "def normalize_landmarks(landmarks):\n",
        "    min_val = np.min(landmarks)\n",
        "    max_val = np.max(landmarks)\n",
        "    if max_val > min_val:\n",
        "        return (landmarks - min_val) / (max_val - min_val)\n",
        "    return landmarks\n",
        "\n",
        "\n",
        "def augment_sequence(sequence):\n",
        "    augmented = [sequence]  \n",
        "    \n",
        "\n",
        "    if len(sequence) >= 10:\n",
        "        # slow\n",
        "        slow = []\n",
        "        for i in range(len(sequence)):\n",
        "            slow.append(sequence[i])\n",
        "            # duplicate every third frame to create a slower sequence\n",
        "            if i % 3 == 0 and i > 0:\n",
        "                slow.append(sequence[i])\n",
        "        augmented.append(slow[:30])  \n",
        "        \n",
        "        # speed up\n",
        "        if len(sequence) >= 15:\n",
        "            fast = sequence[::2]  \n",
        "            augmented.append(fast)\n",
        "            \n",
        "        noise_level = 0.03  # 3% noise\n",
        "        noisy = []\n",
        "        for frame in sequence:\n",
        "            frame_array = np.array(frame)\n",
        "            noise = np.random.normal(0, noise_level, frame_array.shape)\n",
        "            noisy_frame = frame_array + noise\n",
        "            noisy.append(noisy_frame)\n",
        "        augmented.append(noisy)\n",
        "    \n",
        "    return augmented\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 0/2000 classes (0.0%)\n",
            "Progress: Processed 5000 videos so far\n",
            "Progress: Processed 10000 videos so far\n",
            "Progress: Processed 15000 videos so far\n",
            "Progress: Processed 20000 videos so far\n",
            "Progress: Processed 25000 videos so far\n",
            "Progress: 1000/2000 classes (50.0%)\n",
            "Progress: Processed 30000 videos so far\n",
            "Progress: Processed 35000 videos so far\n",
            "Progress: Processed 40000 videos so far\n",
            "Successfully saved processed data and label map\n"
          ]
        }
      ],
      "source": [
        "processed_data = process_wlasl_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = 'data/processed_data/processed_wlasl_full.pickle'\n",
        "MODEL_PATH = 'models/'\n",
        "LABEL_MAP_PATH = 'data/processed_data/label_map_full.json'\n",
        "\n",
        "\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "with open(DATA_PATH, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "with open(LABEL_MAP_PATH, 'r') as f:\n",
        "    label_map = json.load(f)\n",
        "\n",
        "\n",
        "id_to_label = {v: k for k, v in label_map.items()}\n",
        "\n",
        "X = np.array(data['data'])\n",
        "y = np.array(data['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_samples = X.shape[0]\n",
        "timesteps = X.shape[1]\n",
        "features = X.shape[2]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "num_classes = len(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== IMPROVED HIERARCHICAL CLASSIFICATION ===\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, Flatten, Conv1D, GlobalMaxPooling1D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras import metrics\n",
        "import numpy as np\n",
        "\n",
        "def create_hierarchical_labels(y_train, y_val, n_super_classes=50):\n",
        "    all_classes = np.unique(np.concatenate([y_train, y_val]))\n",
        "    n_fine_classes = len(all_classes)\n",
        "    \n",
        "    print(f\"Total unique classes: {n_fine_classes}\")\n",
        "    print(f\"Class range: {all_classes.min()} to {all_classes.max()}\")\n",
        "    \n",
        "    # Map original labels to continuous [0, n_fine_classes)\n",
        "    class_mapping = {old_label: new_label for new_label, old_label in enumerate(all_classes)}\n",
        "    \n",
        "    y_train_mapped = np.array([class_mapping[label] for label in y_train])\n",
        "    y_val_mapped = np.array([class_mapping[label] for label in y_val])\n",
        "    \n",
        "    # Create super-class mapping (group consecutive fine classes)\n",
        "    actual_n_super = min(n_super_classes, n_fine_classes)\n",
        "    classes_per_super = n_fine_classes // actual_n_super\n",
        "    \n",
        "    super_mapping = {}\n",
        "    for fine_idx in range(n_fine_classes):\n",
        "        super_idx = min(fine_idx // classes_per_super, actual_n_super - 1)\n",
        "        super_mapping[fine_idx] = super_idx\n",
        "    \n",
        "    y_train_super = np.array([super_mapping[label] for label in y_train_mapped])\n",
        "    y_val_super = np.array([super_mapping[label] for label in y_val_mapped])\n",
        "    \n",
        "    print(f\"Created {actual_n_super} super-classes from {n_fine_classes} fine classes\")\n",
        "    print(f\"Super-class range: {y_train_super.min()} to {y_train_super.max()}\")\n",
        "    print(f\"Fine-class range: {y_train_mapped.min()} to {y_train_mapped.max()}\")\n",
        "    \n",
        "    return (y_train_super, y_val_super, y_train_mapped, y_val_mapped, \n",
        "            actual_n_super, n_fine_classes)\n",
        "\n",
        "def create_model(input_shape, n_super_classes, n_fine_classes):\n",
        "    inputs = Input(shape=input_shape, name='input_data')\n",
        "    \n",
        "    if len(input_shape) == 2:  \n",
        "        conv1 = Conv1D(64, 3, activation='relu', padding='same')(inputs)\n",
        "        conv1 = BatchNormalization()(conv1)\n",
        "        conv1 = Dropout(0.1)(conv1)\n",
        "        \n",
        "        conv2 = Conv1D(128, 5, activation='relu', padding='same')(conv1)\n",
        "        conv2 = BatchNormalization()(conv2)\n",
        "        conv2 = Dropout(0.1)(conv2)\n",
        "        \n",
        "        conv3 = Conv1D(256, 3, activation='relu', padding='same')(conv2)\n",
        "        conv3 = BatchNormalization()(conv3)\n",
        "        conv3 = Dropout(0.2)(conv3)\n",
        "        \n",
        "        x = GlobalMaxPooling1D()(conv3)\n",
        "    else:\n",
        "        x = Flatten()(inputs)\n",
        "    \n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    \n",
        "    shared_features = Dense(256, activation='relu')(x)\n",
        "    shared_features = BatchNormalization()(shared_features)\n",
        "    shared_features = Dropout(0.2)(shared_features)\n",
        "    \n",
        "    super_branch = Dense(128, activation='relu')(shared_features)\n",
        "    super_branch = BatchNormalization()(super_branch)\n",
        "    super_branch = Dropout(0.2)(super_branch)\n",
        "    \n",
        "    super_output = Dense(n_super_classes, activation='softmax', name='super_output')(super_branch)\n",
        "    \n",
        "    fine_input = tf.keras.layers.Concatenate()([shared_features, super_branch])\n",
        "    \n",
        "    fine_branch = Dense(512, activation='relu')(fine_input)\n",
        "    fine_branch = BatchNormalization()(fine_branch)\n",
        "    fine_branch = Dropout(0.3)(fine_branch)\n",
        "    \n",
        "    fine_branch = Dense(256, activation='relu')(fine_branch)\n",
        "    fine_branch = BatchNormalization()(fine_branch)\n",
        "    fine_branch = Dropout(0.3)(fine_branch)\n",
        "    \n",
        "    fine_output = Dense(n_fine_classes, activation='softmax', name='fine_output')(fine_branch)\n",
        "    \n",
        "    model = Model(inputs, [super_output, fine_output], name='hierarchical_classifier')\n",
        "    \n",
        "    print(f\"Model created: Super({n_super_classes}), Fine({n_fine_classes})\")\n",
        "    return model\n",
        "\n",
        "def train_hierarchical_model(X_train, y_train, X_val, y_val, n_super_classes=50):\n",
        "\n",
        "    print(\"=== DATA PREPROCESSING ===\")\n",
        "    print(f\"Training data shape: {X_train.shape}\")\n",
        "    print(f\"Training labels shape: {y_train.shape}\")\n",
        "    \n",
        "    result = create_hierarchical_labels(y_train, y_val, n_super_classes)\n",
        "    (y_train_super, y_val_super, y_train_fine, y_val_fine, \n",
        "     actual_n_super, n_fine_classes) = result\n",
        "   \n",
        "    y_train_super = y_train_super.astype(np.int32)\n",
        "    y_val_super = y_val_super.astype(np.int32)\n",
        "    y_train_fine = y_train_fine.astype(np.int32)\n",
        "    y_val_fine = y_val_fine.astype(np.int32)\n",
        "    \n",
        "    print(f\"Label statistics:\")\n",
        "    print(f\"  Super classes: {len(np.unique(y_train_super))} unique\")\n",
        "    print(f\"  Fine classes: {len(np.unique(y_train_fine))} unique\")\n",
        "\n",
        "    model = create_model(X_train.shape[1:], actual_n_super, n_fine_classes)\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss=['sparse_categorical_crossentropy', 'sparse_categorical_crossentropy'],\n",
        "        loss_weights=[0.3, 0.7],\n",
        "        metrics=[\n",
        "            ['accuracy'],\n",
        "            ['accuracy', metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_accuracy')]\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    train_labels = [y_train_super, y_train_fine]\n",
        "    val_labels = [y_val_super, y_val_fine]\n",
        "    \n",
        "    print(\"\\n=== FULL TRAINING ===\")\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_fine_output_accuracy', \n",
        "            patience=20, \n",
        "            restore_best_weights=True, \n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_fine_output_loss', \n",
        "            patience=10, \n",
        "            factor=0.3, \n",
        "            min_lr=1e-6,\n",
        "            mode='min',\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    history = model.fit(\n",
        "        X_train, train_labels,\n",
        "        validation_data=(X_val, val_labels),\n",
        "        epochs=200,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    print(\"\\n=== FINAL EVALUATION ===\")\n",
        "    final_metrics = model.evaluate(X_val, val_labels, verbose=1)\n",
        "    \n",
        "    print(\"\\n=== RESULTS ===\")\n",
        "    metric_names = model.metrics_names\n",
        "    for name, value in zip(metric_names, final_metrics):\n",
        "        if 'accuracy' in name:\n",
        "            print(f\"{name}: {value:.4f} ({value*100:.2f}%)\")\n",
        "        else:\n",
        "            print(f\"{name}: {value:.4f}\")\n",
        "    \n",
        "    return model, history\n",
        "\n",
        "\n",
        "def run_hierarchical_classification(X_train, y_train, X_val, y_val, n_super_classes=50):\n",
        "    if X_train.max() > 1.0:\n",
        "        print(\"Normalizing input data...\")\n",
        "        X_train = X_train / X_train.max()\n",
        "        X_val = X_val / X_val.max()\n",
        "    \n",
        "    model, history = train_hierarchical_model(\n",
        "        X_train, y_train, X_val, y_val, n_super_classes\n",
        "    )\n",
        "    \n",
        "    if model is not None:\n",
        "        model.save('hierarchical_model.keras')\n",
        "        print(\"✓ Model saved as 'hierarchical_model.keras'\")\n",
        "    \n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== IMPROVED HIERARCHICAL CLASSIFICATION ===\n",
            "Normalizing input data...\n",
            "=== DATA PREPROCESSING ===\n",
            "Training data shape: (35552, 30, 126)\n",
            "Training labels shape: (35552,)\n",
            "Total unique classes: 2000\n",
            "Class range: 0 to 1999\n",
            "Created 50 super-classes from 2000 fine classes\n",
            "Super-class range: 0 to 49\n",
            "Fine-class range: 0 to 1999\n",
            "Label statistics:\n",
            "  Super classes: 50 unique\n",
            "  Fine classes: 2000 unique\n",
            "Model created: Super(50), Fine(2000)\n",
            "\n",
            "=== MODEL ARCHITECTURE ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"hierarchical_classifier\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"hierarchical_classifier\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_data          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,256</span> │ input_data[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ super_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,450</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fine_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">514,000</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_data          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m126\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m24,256\u001b[0m │ input_data[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m256\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m41,088\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m98,560\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m131,584\u001b[0m │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m197,120\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ super_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │      \u001b[38;5;34m6,450\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ fine_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │    \u001b[38;5;34m514,000\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,317,058</span> (5.02 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,317,058\u001b[0m (5.02 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,834</span> (5.01 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,312,834\u001b[0m (5.01 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> (16.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,224\u001b[0m (16.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== SMALL BATCH TEST ===\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 77ms/step - fine_output_accuracy: 0.0000e+00 - fine_output_loss: 5.4893 - fine_output_top_5_accuracy: 0.0000e+00 - loss: 6.8308 - super_output_accuracy: 0.0000e+00 - super_output_loss: 1.3415\n",
            "✓ Small batch test PASSED!\n",
            "\n",
            "=== FULL TRAINING ===\n",
            "Epoch 1/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 73ms/step - fine_output_accuracy: 0.0017 - fine_output_loss: 5.2497 - fine_output_top_5_accuracy: 0.0083 - loss: 6.5321 - super_output_accuracy: 0.0237 - super_output_loss: 1.2825 - val_fine_output_accuracy: 0.0041 - val_fine_output_loss: 4.8857 - val_fine_output_top_5_accuracy: 0.0178 - val_loss: 6.0700 - val_super_output_accuracy: 0.0299 - val_super_output_loss: 1.1844 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 60ms/step - fine_output_accuracy: 0.0051 - fine_output_loss: 4.7185 - fine_output_top_5_accuracy: 0.0277 - loss: 5.9011 - super_output_accuracy: 0.0328 - super_output_loss: 1.1826 - val_fine_output_accuracy: 0.0093 - val_fine_output_loss: 4.5502 - val_fine_output_top_5_accuracy: 0.0397 - val_loss: 5.7174 - val_super_output_accuracy: 0.0384 - val_super_output_loss: 1.1673 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 61ms/step - fine_output_accuracy: 0.0101 - fine_output_loss: 4.4730 - fine_output_top_5_accuracy: 0.0385 - loss: 5.6383 - super_output_accuracy: 0.0370 - super_output_loss: 1.1653 - val_fine_output_accuracy: 0.0104 - val_fine_output_loss: 4.5345 - val_fine_output_top_5_accuracy: 0.0457 - val_loss: 5.7019 - val_super_output_accuracy: 0.0379 - val_super_output_loss: 1.1674 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 60ms/step - fine_output_accuracy: 0.0166 - fine_output_loss: 4.2811 - fine_output_top_5_accuracy: 0.0609 - loss: 5.4380 - super_output_accuracy: 0.0413 - super_output_loss: 1.1569 - val_fine_output_accuracy: 0.0082 - val_fine_output_loss: 4.7826 - val_fine_output_top_5_accuracy: 0.0381 - val_loss: 5.9477 - val_super_output_accuracy: 0.0384 - val_super_output_loss: 1.1651 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 62ms/step - fine_output_accuracy: 0.0225 - fine_output_loss: 4.0593 - fine_output_top_5_accuracy: 0.0904 - loss: 5.2080 - super_output_accuracy: 0.0430 - super_output_loss: 1.1487 - val_fine_output_accuracy: 0.0237 - val_fine_output_loss: 4.2440 - val_fine_output_top_5_accuracy: 0.1086 - val_loss: 5.4110 - val_super_output_accuracy: 0.0459 - val_super_output_loss: 1.1667 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 102ms/step - fine_output_accuracy: 0.0343 - fine_output_loss: 3.8301 - fine_output_top_5_accuracy: 0.1304 - loss: 4.9694 - super_output_accuracy: 0.0516 - super_output_loss: 1.1393 - val_fine_output_accuracy: 0.0326 - val_fine_output_loss: 4.0167 - val_fine_output_top_5_accuracy: 0.1233 - val_loss: 5.1670 - val_super_output_accuracy: 0.0459 - val_super_output_loss: 1.1503 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 102ms/step - fine_output_accuracy: 0.0490 - fine_output_loss: 3.6426 - fine_output_top_5_accuracy: 0.1711 - loss: 4.7763 - super_output_accuracy: 0.0518 - super_output_loss: 1.1337 - val_fine_output_accuracy: 0.0183 - val_fine_output_loss: 4.3244 - val_fine_output_top_5_accuracy: 0.0824 - val_loss: 5.4940 - val_super_output_accuracy: 0.0444 - val_super_output_loss: 1.1695 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 63ms/step - fine_output_accuracy: 0.0645 - fine_output_loss: 3.4507 - fine_output_top_5_accuracy: 0.2159 - loss: 4.5783 - super_output_accuracy: 0.0583 - super_output_loss: 1.1276 - val_fine_output_accuracy: 0.0231 - val_fine_output_loss: 4.2548 - val_fine_output_top_5_accuracy: 0.1018 - val_loss: 5.4273 - val_super_output_accuracy: 0.0460 - val_super_output_loss: 1.1725 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 69ms/step - fine_output_accuracy: 0.0789 - fine_output_loss: 3.3084 - fine_output_top_5_accuracy: 0.2531 - loss: 4.4313 - super_output_accuracy: 0.0614 - super_output_loss: 1.1229 - val_fine_output_accuracy: 0.0548 - val_fine_output_loss: 3.8167 - val_fine_output_top_5_accuracy: 0.1788 - val_loss: 4.9649 - val_super_output_accuracy: 0.0558 - val_super_output_loss: 1.1481 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - fine_output_accuracy: 0.0965 - fine_output_loss: 3.1838 - fine_output_top_5_accuracy: 0.2911 - loss: 4.2987 - super_output_accuracy: 0.0655 - super_output_loss: 1.1149 - val_fine_output_accuracy: 0.0543 - val_fine_output_loss: 3.7547 - val_fine_output_top_5_accuracy: 0.1844 - val_loss: 4.8990 - val_super_output_accuracy: 0.0600 - val_super_output_loss: 1.1442 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 73ms/step - fine_output_accuracy: 0.1121 - fine_output_loss: 3.0748 - fine_output_top_5_accuracy: 0.3154 - loss: 4.1855 - super_output_accuracy: 0.0693 - super_output_loss: 1.1107 - val_fine_output_accuracy: 0.0840 - val_fine_output_loss: 3.3697 - val_fine_output_top_5_accuracy: 0.2593 - val_loss: 4.4915 - val_super_output_accuracy: 0.0640 - val_super_output_loss: 1.1220 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 72ms/step - fine_output_accuracy: 0.1250 - fine_output_loss: 2.9730 - fine_output_top_5_accuracy: 0.3471 - loss: 4.0794 - super_output_accuracy: 0.0737 - super_output_loss: 1.1064 - val_fine_output_accuracy: 0.0975 - val_fine_output_loss: 3.3333 - val_fine_output_top_5_accuracy: 0.2905 - val_loss: 4.4561 - val_super_output_accuracy: 0.0676 - val_super_output_loss: 1.1228 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 75ms/step - fine_output_accuracy: 0.1418 - fine_output_loss: 2.8677 - fine_output_top_5_accuracy: 0.3820 - loss: 3.9687 - super_output_accuracy: 0.0764 - super_output_loss: 1.1010 - val_fine_output_accuracy: 0.1230 - val_fine_output_loss: 3.1025 - val_fine_output_top_5_accuracy: 0.3482 - val_loss: 4.2122 - val_super_output_accuracy: 0.0761 - val_super_output_loss: 1.1094 - learning_rate: 0.0010\n",
            "Epoch 14/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 71ms/step - fine_output_accuracy: 0.1550 - fine_output_loss: 2.7831 - fine_output_top_5_accuracy: 0.4087 - loss: 3.8791 - super_output_accuracy: 0.0785 - super_output_loss: 1.0960 - val_fine_output_accuracy: 0.0996 - val_fine_output_loss: 3.2928 - val_fine_output_top_5_accuracy: 0.3132 - val_loss: 4.4047 - val_super_output_accuracy: 0.0746 - val_super_output_loss: 1.1116 - learning_rate: 0.0010\n",
            "Epoch 15/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - fine_output_accuracy: 0.1608 - fine_output_loss: 2.7473 - fine_output_top_5_accuracy: 0.4192 - loss: 3.8425 - super_output_accuracy: 0.0797 - super_output_loss: 1.0952 - val_fine_output_accuracy: 0.1232 - val_fine_output_loss: 3.2077 - val_fine_output_top_5_accuracy: 0.3376 - val_loss: 4.3199 - val_super_output_accuracy: 0.0684 - val_super_output_loss: 1.1124 - learning_rate: 0.0010\n",
            "Epoch 16/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 75ms/step - fine_output_accuracy: 0.1704 - fine_output_loss: 2.6818 - fine_output_top_5_accuracy: 0.4414 - loss: 3.7714 - super_output_accuracy: 0.0803 - super_output_loss: 1.0896 - val_fine_output_accuracy: 0.1221 - val_fine_output_loss: 3.3610 - val_fine_output_top_5_accuracy: 0.3427 - val_loss: 4.5049 - val_super_output_accuracy: 0.0765 - val_super_output_loss: 1.1436 - learning_rate: 0.0010\n",
            "Epoch 17/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 80ms/step - fine_output_accuracy: 0.1831 - fine_output_loss: 2.6241 - fine_output_top_5_accuracy: 0.4632 - loss: 3.7114 - super_output_accuracy: 0.0817 - super_output_loss: 1.0873 - val_fine_output_accuracy: 0.1277 - val_fine_output_loss: 3.4280 - val_fine_output_top_5_accuracy: 0.3598 - val_loss: 4.6097 - val_super_output_accuracy: 0.0775 - val_super_output_loss: 1.1813 - learning_rate: 0.0010\n",
            "Epoch 18/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 74ms/step - fine_output_accuracy: 0.1964 - fine_output_loss: 2.5687 - fine_output_top_5_accuracy: 0.4740 - loss: 3.6538 - super_output_accuracy: 0.0856 - super_output_loss: 1.0851 - val_fine_output_accuracy: 0.1414 - val_fine_output_loss: 3.2283 - val_fine_output_top_5_accuracy: 0.3745 - val_loss: 4.3599 - val_super_output_accuracy: 0.0756 - val_super_output_loss: 1.1315 - learning_rate: 0.0010\n",
            "Epoch 19/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 128ms/step - fine_output_accuracy: 0.2056 - fine_output_loss: 2.5169 - fine_output_top_5_accuracy: 0.4957 - loss: 3.5978 - super_output_accuracy: 0.0868 - super_output_loss: 1.0809 - val_fine_output_accuracy: 0.0879 - val_fine_output_loss: 3.4281 - val_fine_output_top_5_accuracy: 0.2710 - val_loss: 4.5546 - val_super_output_accuracy: 0.0691 - val_super_output_loss: 1.1263 - learning_rate: 0.0010\n",
            "Epoch 20/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 100ms/step - fine_output_accuracy: 0.2131 - fine_output_loss: 2.4729 - fine_output_top_5_accuracy: 0.5094 - loss: 3.5498 - super_output_accuracy: 0.0915 - super_output_loss: 1.0769 - val_fine_output_accuracy: 0.1510 - val_fine_output_loss: 2.9173 - val_fine_output_top_5_accuracy: 0.4091 - val_loss: 4.0131 - val_super_output_accuracy: 0.0799 - val_super_output_loss: 1.0956 - learning_rate: 0.0010\n",
            "Epoch 21/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 86ms/step - fine_output_accuracy: 0.2248 - fine_output_loss: 2.4354 - fine_output_top_5_accuracy: 0.5178 - loss: 3.5111 - super_output_accuracy: 0.0939 - super_output_loss: 1.0757 - val_fine_output_accuracy: 0.1469 - val_fine_output_loss: 3.2387 - val_fine_output_top_5_accuracy: 0.3960 - val_loss: 4.3639 - val_super_output_accuracy: 0.0837 - val_super_output_loss: 1.1248 - learning_rate: 0.0010\n",
            "Epoch 22/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - fine_output_accuracy: 0.2313 - fine_output_loss: 2.3952 - fine_output_top_5_accuracy: 0.5307 - loss: 3.4642 - super_output_accuracy: 0.0972 - super_output_loss: 1.0690 - val_fine_output_accuracy: 0.1538 - val_fine_output_loss: 2.9168 - val_fine_output_top_5_accuracy: 0.4066 - val_loss: 4.0061 - val_super_output_accuracy: 0.0847 - val_super_output_loss: 1.0891 - learning_rate: 0.0010\n",
            "Epoch 23/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 65ms/step - fine_output_accuracy: 0.2383 - fine_output_loss: 2.3576 - fine_output_top_5_accuracy: 0.5404 - loss: 3.4274 - super_output_accuracy: 0.0955 - super_output_loss: 1.0698 - val_fine_output_accuracy: 0.1249 - val_fine_output_loss: 3.1424 - val_fine_output_top_5_accuracy: 0.3437 - val_loss: 4.2475 - val_super_output_accuracy: 0.0761 - val_super_output_loss: 1.1051 - learning_rate: 0.0010\n",
            "Epoch 24/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 67ms/step - fine_output_accuracy: 0.2370 - fine_output_loss: 2.3481 - fine_output_top_5_accuracy: 0.5509 - loss: 3.4142 - super_output_accuracy: 0.0983 - super_output_loss: 1.0661 - val_fine_output_accuracy: 0.1787 - val_fine_output_loss: 2.8128 - val_fine_output_top_5_accuracy: 0.4562 - val_loss: 3.8967 - val_super_output_accuracy: 0.0912 - val_super_output_loss: 1.0837 - learning_rate: 0.0010\n",
            "Epoch 25/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 110ms/step - fine_output_accuracy: 0.2558 - fine_output_loss: 2.3062 - fine_output_top_5_accuracy: 0.5608 - loss: 3.3703 - super_output_accuracy: 0.1003 - super_output_loss: 1.0641 - val_fine_output_accuracy: 0.1653 - val_fine_output_loss: 2.8032 - val_fine_output_top_5_accuracy: 0.4405 - val_loss: 3.8828 - val_super_output_accuracy: 0.0920 - val_super_output_loss: 1.0797 - learning_rate: 0.0010\n",
            "Epoch 26/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 118ms/step - fine_output_accuracy: 0.2585 - fine_output_loss: 2.2776 - fine_output_top_5_accuracy: 0.5677 - loss: 3.3385 - super_output_accuracy: 0.1025 - super_output_loss: 1.0609 - val_fine_output_accuracy: 0.1604 - val_fine_output_loss: 2.8440 - val_fine_output_top_5_accuracy: 0.4212 - val_loss: 3.9269 - val_super_output_accuracy: 0.0924 - val_super_output_loss: 1.0830 - learning_rate: 0.0010\n",
            "Epoch 27/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 90ms/step - fine_output_accuracy: 0.2708 - fine_output_loss: 2.2408 - fine_output_top_5_accuracy: 0.5833 - loss: 3.2997 - super_output_accuracy: 0.1029 - super_output_loss: 1.0589 - val_fine_output_accuracy: 0.1457 - val_fine_output_loss: 3.0055 - val_fine_output_top_5_accuracy: 0.3780 - val_loss: 4.0934 - val_super_output_accuracy: 0.0879 - val_super_output_loss: 1.0879 - learning_rate: 0.0010\n",
            "Epoch 28/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 94ms/step - fine_output_accuracy: 0.2747 - fine_output_loss: 2.2073 - fine_output_top_5_accuracy: 0.5898 - loss: 3.2665 - super_output_accuracy: 0.1026 - super_output_loss: 1.0591 - val_fine_output_accuracy: 0.1651 - val_fine_output_loss: 2.8423 - val_fine_output_top_5_accuracy: 0.4327 - val_loss: 3.9234 - val_super_output_accuracy: 0.0889 - val_super_output_loss: 1.0810 - learning_rate: 0.0010\n",
            "Epoch 29/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 91ms/step - fine_output_accuracy: 0.2800 - fine_output_loss: 2.1913 - fine_output_top_5_accuracy: 0.5977 - loss: 3.2468 - super_output_accuracy: 0.1064 - super_output_loss: 1.0555 - val_fine_output_accuracy: 0.1586 - val_fine_output_loss: 2.8664 - val_fine_output_top_5_accuracy: 0.4202 - val_loss: 3.9455 - val_super_output_accuracy: 0.0916 - val_super_output_loss: 1.0792 - learning_rate: 0.0010\n",
            "Epoch 30/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - fine_output_accuracy: 0.2736 - fine_output_loss: 2.1977 - fine_output_top_5_accuracy: 0.5985 - loss: 3.2507 - super_output_accuracy: 0.1049 - super_output_loss: 1.0531 - val_fine_output_accuracy: 0.1760 - val_fine_output_loss: 2.7420 - val_fine_output_top_5_accuracy: 0.4561 - val_loss: 3.8150 - val_super_output_accuracy: 0.0981 - val_super_output_loss: 1.0729 - learning_rate: 0.0010\n",
            "Epoch 31/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 68ms/step - fine_output_accuracy: 0.2887 - fine_output_loss: 2.1545 - fine_output_top_5_accuracy: 0.6069 - loss: 3.2077 - super_output_accuracy: 0.1058 - super_output_loss: 1.0532 - val_fine_output_accuracy: 0.1583 - val_fine_output_loss: 2.8640 - val_fine_output_top_5_accuracy: 0.4173 - val_loss: 3.9407 - val_super_output_accuracy: 0.0902 - val_super_output_loss: 1.0767 - learning_rate: 0.0010\n",
            "Epoch 32/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 69ms/step - fine_output_accuracy: 0.2913 - fine_output_loss: 2.1399 - fine_output_top_5_accuracy: 0.6083 - loss: 3.1951 - super_output_accuracy: 0.1006 - super_output_loss: 1.0551 - val_fine_output_accuracy: 0.1579 - val_fine_output_loss: 2.8521 - val_fine_output_top_5_accuracy: 0.4189 - val_loss: 3.9238 - val_super_output_accuracy: 0.0943 - val_super_output_loss: 1.0717 - learning_rate: 0.0010\n",
            "Epoch 33/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 69ms/step - fine_output_accuracy: 0.3025 - fine_output_loss: 2.0989 - fine_output_top_5_accuracy: 0.6220 - loss: 3.1460 - super_output_accuracy: 0.1098 - super_output_loss: 1.0471 - val_fine_output_accuracy: 0.1553 - val_fine_output_loss: 2.9258 - val_fine_output_top_5_accuracy: 0.4017 - val_loss: 4.0095 - val_super_output_accuracy: 0.0907 - val_super_output_loss: 1.0837 - learning_rate: 0.0010\n",
            "Epoch 34/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 95ms/step - fine_output_accuracy: 0.3067 - fine_output_loss: 2.0799 - fine_output_top_5_accuracy: 0.6301 - loss: 3.1266 - super_output_accuracy: 0.1093 - super_output_loss: 1.0467 - val_fine_output_accuracy: 0.1667 - val_fine_output_loss: 2.8356 - val_fine_output_top_5_accuracy: 0.4362 - val_loss: 3.9078 - val_super_output_accuracy: 0.0962 - val_super_output_loss: 1.0725 - learning_rate: 0.0010\n",
            "Epoch 35/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 84ms/step - fine_output_accuracy: 0.3087 - fine_output_loss: 2.0690 - fine_output_top_5_accuracy: 0.6302 - loss: 3.1147 - super_output_accuracy: 0.1122 - super_output_loss: 1.0457 - val_fine_output_accuracy: 0.1484 - val_fine_output_loss: 2.9474 - val_fine_output_top_5_accuracy: 0.3985 - val_loss: 4.0262 - val_super_output_accuracy: 0.0907 - val_super_output_loss: 1.0788 - learning_rate: 0.0010\n",
            "Epoch 36/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 92ms/step - fine_output_accuracy: 0.3198 - fine_output_loss: 2.0384 - fine_output_top_5_accuracy: 0.6416 - loss: 3.0806 - super_output_accuracy: 0.1130 - super_output_loss: 1.0423 - val_fine_output_accuracy: 0.2279 - val_fine_output_loss: 2.5398 - val_fine_output_top_5_accuracy: 0.5314 - val_loss: 3.6024 - val_super_output_accuracy: 0.1076 - val_super_output_loss: 1.0627 - learning_rate: 0.0010\n",
            "Epoch 37/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 67ms/step - fine_output_accuracy: 0.3213 - fine_output_loss: 2.0321 - fine_output_top_5_accuracy: 0.6429 - loss: 3.0718 - super_output_accuracy: 0.1121 - super_output_loss: 1.0396 - val_fine_output_accuracy: 0.1675 - val_fine_output_loss: 2.8338 - val_fine_output_top_5_accuracy: 0.4363 - val_loss: 3.9104 - val_super_output_accuracy: 0.0927 - val_super_output_loss: 1.0768 - learning_rate: 0.0010\n",
            "Epoch 38/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 84ms/step - fine_output_accuracy: 0.3164 - fine_output_loss: 2.0407 - fine_output_top_5_accuracy: 0.6445 - loss: 3.0835 - super_output_accuracy: 0.1112 - super_output_loss: 1.0427 - val_fine_output_accuracy: 0.1627 - val_fine_output_loss: 2.8229 - val_fine_output_top_5_accuracy: 0.4343 - val_loss: 3.8943 - val_super_output_accuracy: 0.0980 - val_super_output_loss: 1.0715 - learning_rate: 0.0010\n",
            "Epoch 39/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 85ms/step - fine_output_accuracy: 0.3286 - fine_output_loss: 1.9979 - fine_output_top_5_accuracy: 0.6514 - loss: 3.0378 - super_output_accuracy: 0.1128 - super_output_loss: 1.0399 - val_fine_output_accuracy: 0.1987 - val_fine_output_loss: 2.6597 - val_fine_output_top_5_accuracy: 0.4894 - val_loss: 3.7190 - val_super_output_accuracy: 0.1058 - val_super_output_loss: 1.0592 - learning_rate: 0.0010\n",
            "Epoch 40/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 83ms/step - fine_output_accuracy: 0.3298 - fine_output_loss: 1.9876 - fine_output_top_5_accuracy: 0.6540 - loss: 3.0277 - super_output_accuracy: 0.1157 - super_output_loss: 1.0401 - val_fine_output_accuracy: 0.2212 - val_fine_output_loss: 2.5407 - val_fine_output_top_5_accuracy: 0.5209 - val_loss: 3.5955 - val_super_output_accuracy: 0.1115 - val_super_output_loss: 1.0547 - learning_rate: 0.0010\n",
            "Epoch 41/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 88ms/step - fine_output_accuracy: 0.3320 - fine_output_loss: 1.9840 - fine_output_top_5_accuracy: 0.6597 - loss: 3.0212 - super_output_accuracy: 0.1194 - super_output_loss: 1.0372 - val_fine_output_accuracy: 0.2033 - val_fine_output_loss: 2.6632 - val_fine_output_top_5_accuracy: 0.4874 - val_loss: 3.7263 - val_super_output_accuracy: 0.1011 - val_super_output_loss: 1.0631 - learning_rate: 0.0010\n",
            "Epoch 42/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 83ms/step - fine_output_accuracy: 0.3361 - fine_output_loss: 1.9573 - fine_output_top_5_accuracy: 0.6674 - loss: 2.9952 - super_output_accuracy: 0.1164 - super_output_loss: 1.0379 - val_fine_output_accuracy: 0.1745 - val_fine_output_loss: 2.7807 - val_fine_output_top_5_accuracy: 0.4434 - val_loss: 3.8477 - val_super_output_accuracy: 0.1010 - val_super_output_loss: 1.0670 - learning_rate: 0.0010\n",
            "Epoch 43/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 85ms/step - fine_output_accuracy: 0.3473 - fine_output_loss: 1.9332 - fine_output_top_5_accuracy: 0.6716 - loss: 2.9642 - super_output_accuracy: 0.1187 - super_output_loss: 1.0310 - val_fine_output_accuracy: 0.1973 - val_fine_output_loss: 2.6749 - val_fine_output_top_5_accuracy: 0.4809 - val_loss: 3.7370 - val_super_output_accuracy: 0.1038 - val_super_output_loss: 1.0620 - learning_rate: 0.0010\n",
            "Epoch 44/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 91ms/step - fine_output_accuracy: 0.3490 - fine_output_loss: 1.9319 - fine_output_top_5_accuracy: 0.6716 - loss: 2.9657 - super_output_accuracy: 0.1168 - super_output_loss: 1.0338 - val_fine_output_accuracy: 0.2322 - val_fine_output_loss: 2.5118 - val_fine_output_top_5_accuracy: 0.5365 - val_loss: 3.5689 - val_super_output_accuracy: 0.1069 - val_super_output_loss: 1.0571 - learning_rate: 0.0010\n",
            "Epoch 45/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 85ms/step - fine_output_accuracy: 0.3474 - fine_output_loss: 1.9266 - fine_output_top_5_accuracy: 0.6801 - loss: 2.9558 - super_output_accuracy: 0.1235 - super_output_loss: 1.0292 - val_fine_output_accuracy: 0.2500 - val_fine_output_loss: 2.4797 - val_fine_output_top_5_accuracy: 0.5594 - val_loss: 3.5366 - val_super_output_accuracy: 0.1078 - val_super_output_loss: 1.0568 - learning_rate: 0.0010\n",
            "Epoch 46/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 69ms/step - fine_output_accuracy: 0.3557 - fine_output_loss: 1.9021 - fine_output_top_5_accuracy: 0.6804 - loss: 2.9355 - super_output_accuracy: 0.1183 - super_output_loss: 1.0334 - val_fine_output_accuracy: 0.1903 - val_fine_output_loss: 2.6970 - val_fine_output_top_5_accuracy: 0.4772 - val_loss: 3.7637 - val_super_output_accuracy: 0.0995 - val_super_output_loss: 1.0667 - learning_rate: 0.0010\n",
            "Epoch 47/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 69ms/step - fine_output_accuracy: 0.3517 - fine_output_loss: 1.9058 - fine_output_top_5_accuracy: 0.6789 - loss: 2.9374 - super_output_accuracy: 0.1192 - super_output_loss: 1.0316 - val_fine_output_accuracy: 0.2508 - val_fine_output_loss: 2.4690 - val_fine_output_top_5_accuracy: 0.5572 - val_loss: 3.5196 - val_super_output_accuracy: 0.1154 - val_super_output_loss: 1.0506 - learning_rate: 0.0010\n",
            "Epoch 48/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 76ms/step - fine_output_accuracy: 0.3534 - fine_output_loss: 1.8941 - fine_output_top_5_accuracy: 0.6852 - loss: 2.9255 - super_output_accuracy: 0.1202 - super_output_loss: 1.0314 - val_fine_output_accuracy: 0.2445 - val_fine_output_loss: 2.4669 - val_fine_output_top_5_accuracy: 0.5498 - val_loss: 3.5182 - val_super_output_accuracy: 0.1151 - val_super_output_loss: 1.0514 - learning_rate: 0.0010\n",
            "Epoch 49/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 78ms/step - fine_output_accuracy: 0.3601 - fine_output_loss: 1.8828 - fine_output_top_5_accuracy: 0.6873 - loss: 2.9050 - super_output_accuracy: 0.1245 - super_output_loss: 1.0222 - val_fine_output_accuracy: 0.2430 - val_fine_output_loss: 2.4969 - val_fine_output_top_5_accuracy: 0.5462 - val_loss: 3.5474 - val_super_output_accuracy: 0.1118 - val_super_output_loss: 1.0506 - learning_rate: 0.0010\n",
            "Epoch 50/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 75ms/step - fine_output_accuracy: 0.3640 - fine_output_loss: 1.8620 - fine_output_top_5_accuracy: 0.6925 - loss: 2.8850 - super_output_accuracy: 0.1250 - super_output_loss: 1.0230 - val_fine_output_accuracy: 0.2360 - val_fine_output_loss: 2.5304 - val_fine_output_top_5_accuracy: 0.5342 - val_loss: 3.5838 - val_super_output_accuracy: 0.1140 - val_super_output_loss: 1.0533 - learning_rate: 0.0010\n",
            "Epoch 51/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 76ms/step - fine_output_accuracy: 0.3627 - fine_output_loss: 1.8566 - fine_output_top_5_accuracy: 0.6932 - loss: 2.8787 - super_output_accuracy: 0.1270 - super_output_loss: 1.0221 - val_fine_output_accuracy: 0.2023 - val_fine_output_loss: 2.6385 - val_fine_output_top_5_accuracy: 0.4990 - val_loss: 3.6980 - val_super_output_accuracy: 0.1058 - val_super_output_loss: 1.0595 - learning_rate: 0.0010\n",
            "Epoch 52/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 77ms/step - fine_output_accuracy: 0.3761 - fine_output_loss: 1.8252 - fine_output_top_5_accuracy: 0.7032 - loss: 2.8505 - super_output_accuracy: 0.1255 - super_output_loss: 1.0253 - val_fine_output_accuracy: 0.2422 - val_fine_output_loss: 2.4997 - val_fine_output_top_5_accuracy: 0.5431 - val_loss: 3.5482 - val_super_output_accuracy: 0.1114 - val_super_output_loss: 1.0486 - learning_rate: 0.0010\n",
            "Epoch 53/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 79ms/step - fine_output_accuracy: 0.3715 - fine_output_loss: 1.8264 - fine_output_top_5_accuracy: 0.7017 - loss: 2.8475 - super_output_accuracy: 0.1276 - super_output_loss: 1.0211 - val_fine_output_accuracy: 0.2687 - val_fine_output_loss: 2.3961 - val_fine_output_top_5_accuracy: 0.5763 - val_loss: 3.4400 - val_super_output_accuracy: 0.1177 - val_super_output_loss: 1.0438 - learning_rate: 0.0010\n",
            "Epoch 54/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 77ms/step - fine_output_accuracy: 0.3792 - fine_output_loss: 1.8069 - fine_output_top_5_accuracy: 0.7056 - loss: 2.8255 - super_output_accuracy: 0.1275 - super_output_loss: 1.0187 - val_fine_output_accuracy: 0.2128 - val_fine_output_loss: 2.6094 - val_fine_output_top_5_accuracy: 0.5100 - val_loss: 3.6661 - val_super_output_accuracy: 0.1046 - val_super_output_loss: 1.0568 - learning_rate: 0.0010\n",
            "Epoch 55/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 78ms/step - fine_output_accuracy: 0.3839 - fine_output_loss: 1.7965 - fine_output_top_5_accuracy: 0.7098 - loss: 2.8136 - super_output_accuracy: 0.1322 - super_output_loss: 1.0171 - val_fine_output_accuracy: 0.2566 - val_fine_output_loss: 2.4412 - val_fine_output_top_5_accuracy: 0.5628 - val_loss: 3.4838 - val_super_output_accuracy: 0.1248 - val_super_output_loss: 1.0425 - learning_rate: 0.0010\n",
            "Epoch 56/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 78ms/step - fine_output_accuracy: 0.3783 - fine_output_loss: 1.8074 - fine_output_top_5_accuracy: 0.7078 - loss: 2.8266 - super_output_accuracy: 0.1277 - super_output_loss: 1.0192 - val_fine_output_accuracy: 0.2185 - val_fine_output_loss: 2.5952 - val_fine_output_top_5_accuracy: 0.5140 - val_loss: 3.6473 - val_super_output_accuracy: 0.1126 - val_super_output_loss: 1.0522 - learning_rate: 0.0010\n",
            "Epoch 57/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 78ms/step - fine_output_accuracy: 0.3822 - fine_output_loss: 1.7867 - fine_output_top_5_accuracy: 0.7092 - loss: 2.8059 - super_output_accuracy: 0.1315 - super_output_loss: 1.0192 - val_fine_output_accuracy: 0.2486 - val_fine_output_loss: 2.4692 - val_fine_output_top_5_accuracy: 0.5498 - val_loss: 3.5171 - val_super_output_accuracy: 0.1130 - val_super_output_loss: 1.0476 - learning_rate: 0.0010\n",
            "Epoch 58/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 78ms/step - fine_output_accuracy: 0.3854 - fine_output_loss: 1.7815 - fine_output_top_5_accuracy: 0.7160 - loss: 2.7982 - super_output_accuracy: 0.1323 - super_output_loss: 1.0167 - val_fine_output_accuracy: 0.2098 - val_fine_output_loss: 2.6269 - val_fine_output_top_5_accuracy: 0.5046 - val_loss: 3.6844 - val_super_output_accuracy: 0.1104 - val_super_output_loss: 1.0576 - learning_rate: 0.0010\n",
            "Epoch 59/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 80ms/step - fine_output_accuracy: 0.3875 - fine_output_loss: 1.7815 - fine_output_top_5_accuracy: 0.7160 - loss: 2.8004 - super_output_accuracy: 0.1314 - super_output_loss: 1.0189 - val_fine_output_accuracy: 0.1951 - val_fine_output_loss: 2.7180 - val_fine_output_top_5_accuracy: 0.4791 - val_loss: 3.7761 - val_super_output_accuracy: 0.1013 - val_super_output_loss: 1.0586 - learning_rate: 0.0010\n",
            "Epoch 60/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 78ms/step - fine_output_accuracy: 0.3991 - fine_output_loss: 1.7480 - fine_output_top_5_accuracy: 0.7183 - loss: 2.7595 - super_output_accuracy: 0.1351 - super_output_loss: 1.0115 - val_fine_output_accuracy: 0.2759 - val_fine_output_loss: 2.3572 - val_fine_output_top_5_accuracy: 0.5896 - val_loss: 3.4011 - val_super_output_accuracy: 0.1189 - val_super_output_loss: 1.0437 - learning_rate: 0.0010\n",
            "Epoch 61/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 74ms/step - fine_output_accuracy: 0.4011 - fine_output_loss: 1.7236 - fine_output_top_5_accuracy: 0.7305 - loss: 2.7348 - super_output_accuracy: 0.1320 - super_output_loss: 1.0112 - val_fine_output_accuracy: 0.2677 - val_fine_output_loss: 2.3701 - val_fine_output_top_5_accuracy: 0.5852 - val_loss: 3.4105 - val_super_output_accuracy: 0.1196 - val_super_output_loss: 1.0405 - learning_rate: 0.0010\n",
            "Epoch 62/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 73ms/step - fine_output_accuracy: 0.3983 - fine_output_loss: 1.7306 - fine_output_top_5_accuracy: 0.7262 - loss: 2.7454 - super_output_accuracy: 0.1363 - super_output_loss: 1.0148 - val_fine_output_accuracy: 0.2825 - val_fine_output_loss: 2.3129 - val_fine_output_top_5_accuracy: 0.6010 - val_loss: 3.3498 - val_super_output_accuracy: 0.1234 - val_super_output_loss: 1.0368 - learning_rate: 0.0010\n",
            "Epoch 63/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 71ms/step - fine_output_accuracy: 0.4007 - fine_output_loss: 1.7252 - fine_output_top_5_accuracy: 0.7299 - loss: 2.7404 - super_output_accuracy: 0.1290 - super_output_loss: 1.0152 - val_fine_output_accuracy: 0.2862 - val_fine_output_loss: 2.3172 - val_fine_output_top_5_accuracy: 0.6038 - val_loss: 3.3519 - val_super_output_accuracy: 0.1264 - val_super_output_loss: 1.0345 - learning_rate: 0.0010\n",
            "Epoch 64/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - fine_output_accuracy: 0.4015 - fine_output_loss: 1.7290 - fine_output_top_5_accuracy: 0.7232 - loss: 2.7402 - super_output_accuracy: 0.1321 - super_output_loss: 1.0113 - val_fine_output_accuracy: 0.2386 - val_fine_output_loss: 2.5347 - val_fine_output_top_5_accuracy: 0.5358 - val_loss: 3.5833 - val_super_output_accuracy: 0.1071 - val_super_output_loss: 1.0486 - learning_rate: 0.0010\n",
            "Epoch 65/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 72ms/step - fine_output_accuracy: 0.4056 - fine_output_loss: 1.7046 - fine_output_top_5_accuracy: 0.7341 - loss: 2.7137 - super_output_accuracy: 0.1335 - super_output_loss: 1.0091 - val_fine_output_accuracy: 0.2467 - val_fine_output_loss: 2.4831 - val_fine_output_top_5_accuracy: 0.5525 - val_loss: 3.5316 - val_super_output_accuracy: 0.1082 - val_super_output_loss: 1.0486 - learning_rate: 0.0010\n",
            "Epoch 66/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 84ms/step - fine_output_accuracy: 0.4080 - fine_output_loss: 1.6974 - fine_output_top_5_accuracy: 0.7347 - loss: 2.7099 - super_output_accuracy: 0.1342 - super_output_loss: 1.0125 - val_fine_output_accuracy: 0.2521 - val_fine_output_loss: 2.4586 - val_fine_output_top_5_accuracy: 0.5581 - val_loss: 3.5028 - val_super_output_accuracy: 0.1148 - val_super_output_loss: 1.0442 - learning_rate: 0.0010\n",
            "Epoch 67/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 84ms/step - fine_output_accuracy: 0.4080 - fine_output_loss: 1.7032 - fine_output_top_5_accuracy: 0.7300 - loss: 2.7160 - super_output_accuracy: 0.1297 - super_output_loss: 1.0128 - val_fine_output_accuracy: 0.2733 - val_fine_output_loss: 2.3695 - val_fine_output_top_5_accuracy: 0.5866 - val_loss: 3.4090 - val_super_output_accuracy: 0.1155 - val_super_output_loss: 1.0396 - learning_rate: 0.0010\n",
            "Epoch 68/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 81ms/step - fine_output_accuracy: 0.4110 - fine_output_loss: 1.6946 - fine_output_top_5_accuracy: 0.7355 - loss: 2.7013 - super_output_accuracy: 0.1353 - super_output_loss: 1.0067 - val_fine_output_accuracy: 0.3012 - val_fine_output_loss: 2.2742 - val_fine_output_top_5_accuracy: 0.6191 - val_loss: 3.3117 - val_super_output_accuracy: 0.1273 - val_super_output_loss: 1.0372 - learning_rate: 0.0010\n",
            "Epoch 69/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 82ms/step - fine_output_accuracy: 0.4099 - fine_output_loss: 1.6907 - fine_output_top_5_accuracy: 0.7376 - loss: 2.6980 - super_output_accuracy: 0.1357 - super_output_loss: 1.0074 - val_fine_output_accuracy: 0.1987 - val_fine_output_loss: 2.7182 - val_fine_output_top_5_accuracy: 0.4722 - val_loss: 3.7783 - val_super_output_accuracy: 0.1020 - val_super_output_loss: 1.0602 - learning_rate: 0.0010\n",
            "Epoch 70/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 90ms/step - fine_output_accuracy: 0.4099 - fine_output_loss: 1.6879 - fine_output_top_5_accuracy: 0.7364 - loss: 2.6951 - super_output_accuracy: 0.1352 - super_output_loss: 1.0072 - val_fine_output_accuracy: 0.2628 - val_fine_output_loss: 2.4177 - val_fine_output_top_5_accuracy: 0.5680 - val_loss: 3.4626 - val_super_output_accuracy: 0.1161 - val_super_output_loss: 1.0447 - learning_rate: 0.0010\n",
            "Epoch 71/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 79ms/step - fine_output_accuracy: 0.4229 - fine_output_loss: 1.6565 - fine_output_top_5_accuracy: 0.7442 - loss: 2.6601 - super_output_accuracy: 0.1400 - super_output_loss: 1.0036 - val_fine_output_accuracy: 0.2713 - val_fine_output_loss: 2.3830 - val_fine_output_top_5_accuracy: 0.5771 - val_loss: 3.4174 - val_super_output_accuracy: 0.1223 - val_super_output_loss: 1.0345 - learning_rate: 0.0010\n",
            "Epoch 72/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 79ms/step - fine_output_accuracy: 0.4192 - fine_output_loss: 1.6555 - fine_output_top_5_accuracy: 0.7498 - loss: 2.6600 - super_output_accuracy: 0.1388 - super_output_loss: 1.0044 - val_fine_output_accuracy: 0.2498 - val_fine_output_loss: 2.4683 - val_fine_output_top_5_accuracy: 0.5594 - val_loss: 3.5171 - val_super_output_accuracy: 0.1135 - val_super_output_loss: 1.0487 - learning_rate: 0.0010\n",
            "Epoch 73/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 80ms/step - fine_output_accuracy: 0.4191 - fine_output_loss: 1.6641 - fine_output_top_5_accuracy: 0.7441 - loss: 2.6686 - super_output_accuracy: 0.1354 - super_output_loss: 1.0045 - val_fine_output_accuracy: 0.2776 - val_fine_output_loss: 2.3687 - val_fine_output_top_5_accuracy: 0.5822 - val_loss: 3.4054 - val_super_output_accuracy: 0.1230 - val_super_output_loss: 1.0367 - learning_rate: 0.0010\n",
            "Epoch 74/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 81ms/step - fine_output_accuracy: 0.4210 - fine_output_loss: 1.6579 - fine_output_top_5_accuracy: 0.7446 - loss: 2.6626 - super_output_accuracy: 0.1392 - super_output_loss: 1.0046 - val_fine_output_accuracy: 0.2417 - val_fine_output_loss: 2.5185 - val_fine_output_top_5_accuracy: 0.5376 - val_loss: 3.5668 - val_super_output_accuracy: 0.1115 - val_super_output_loss: 1.0482 - learning_rate: 0.0010\n",
            "Epoch 75/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 81ms/step - fine_output_accuracy: 0.4240 - fine_output_loss: 1.6515 - fine_output_top_5_accuracy: 0.7488 - loss: 2.6551 - super_output_accuracy: 0.1375 - super_output_loss: 1.0036 - val_fine_output_accuracy: 0.2557 - val_fine_output_loss: 2.4456 - val_fine_output_top_5_accuracy: 0.5577 - val_loss: 3.4856 - val_super_output_accuracy: 0.1157 - val_super_output_loss: 1.0400 - learning_rate: 0.0010\n",
            "Epoch 76/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 86ms/step - fine_output_accuracy: 0.4267 - fine_output_loss: 1.6286 - fine_output_top_5_accuracy: 0.7544 - loss: 2.6287 - super_output_accuracy: 0.1406 - super_output_loss: 1.0001 - val_fine_output_accuracy: 0.2568 - val_fine_output_loss: 2.4170 - val_fine_output_top_5_accuracy: 0.5699 - val_loss: 3.4585 - val_super_output_accuracy: 0.1143 - val_super_output_loss: 1.0416 - learning_rate: 0.0010\n",
            "Epoch 77/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 87ms/step - fine_output_accuracy: 0.4307 - fine_output_loss: 1.6296 - fine_output_top_5_accuracy: 0.7537 - loss: 2.6304 - super_output_accuracy: 0.1397 - super_output_loss: 1.0008 - val_fine_output_accuracy: 0.2787 - val_fine_output_loss: 2.3275 - val_fine_output_top_5_accuracy: 0.5981 - val_loss: 3.3586 - val_super_output_accuracy: 0.1195 - val_super_output_loss: 1.0310 - learning_rate: 0.0010\n",
            "Epoch 78/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - fine_output_accuracy: 0.4368 - fine_output_loss: 1.6084 - fine_output_top_5_accuracy: 0.7546 - loss: 2.6085 - super_output_accuracy: 0.1426 - super_output_loss: 1.0001\n",
            "Epoch 78: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 91ms/step - fine_output_accuracy: 0.4368 - fine_output_loss: 1.6085 - fine_output_top_5_accuracy: 0.7545 - loss: 2.6085 - super_output_accuracy: 0.1426 - super_output_loss: 1.0001 - val_fine_output_accuracy: 0.2753 - val_fine_output_loss: 2.3485 - val_fine_output_top_5_accuracy: 0.5935 - val_loss: 3.3807 - val_super_output_accuracy: 0.1206 - val_super_output_loss: 1.0319 - learning_rate: 0.0010\n",
            "Epoch 79/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 89ms/step - fine_output_accuracy: 0.4561 - fine_output_loss: 1.5409 - fine_output_top_5_accuracy: 0.7727 - loss: 2.5286 - super_output_accuracy: 0.1538 - super_output_loss: 0.9877 - val_fine_output_accuracy: 0.3175 - val_fine_output_loss: 2.2055 - val_fine_output_top_5_accuracy: 0.6270 - val_loss: 3.2264 - val_super_output_accuracy: 0.1337 - val_super_output_loss: 1.0208 - learning_rate: 3.0000e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 88ms/step - fine_output_accuracy: 0.4674 - fine_output_loss: 1.4923 - fine_output_top_5_accuracy: 0.7869 - loss: 2.4784 - super_output_accuracy: 0.1529 - super_output_loss: 0.9861 - val_fine_output_accuracy: 0.3177 - val_fine_output_loss: 2.2128 - val_fine_output_top_5_accuracy: 0.6267 - val_loss: 3.2345 - val_super_output_accuracy: 0.1315 - val_super_output_loss: 1.0217 - learning_rate: 3.0000e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 100ms/step - fine_output_accuracy: 0.4847 - fine_output_loss: 1.4666 - fine_output_top_5_accuracy: 0.7919 - loss: 2.4543 - super_output_accuracy: 0.1511 - super_output_loss: 0.9877 - val_fine_output_accuracy: 0.3348 - val_fine_output_loss: 2.1399 - val_fine_output_top_5_accuracy: 0.6502 - val_loss: 3.1582 - val_super_output_accuracy: 0.1289 - val_super_output_loss: 1.0180 - learning_rate: 3.0000e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 133ms/step - fine_output_accuracy: 0.4865 - fine_output_loss: 1.4556 - fine_output_top_5_accuracy: 0.7924 - loss: 2.4364 - super_output_accuracy: 0.1587 - super_output_loss: 0.9809 - val_fine_output_accuracy: 0.3294 - val_fine_output_loss: 2.1487 - val_fine_output_top_5_accuracy: 0.6487 - val_loss: 3.1644 - val_super_output_accuracy: 0.1359 - val_super_output_loss: 1.0155 - learning_rate: 3.0000e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 135ms/step - fine_output_accuracy: 0.4819 - fine_output_loss: 1.4463 - fine_output_top_5_accuracy: 0.7937 - loss: 2.4272 - super_output_accuracy: 0.1519 - super_output_loss: 0.9809 - val_fine_output_accuracy: 0.3261 - val_fine_output_loss: 2.1624 - val_fine_output_top_5_accuracy: 0.6454 - val_loss: 3.1784 - val_super_output_accuracy: 0.1345 - val_super_output_loss: 1.0159 - learning_rate: 3.0000e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 155ms/step - fine_output_accuracy: 0.4823 - fine_output_loss: 1.4679 - fine_output_top_5_accuracy: 0.7895 - loss: 2.4495 - super_output_accuracy: 0.1546 - super_output_loss: 0.9817 - val_fine_output_accuracy: 0.3225 - val_fine_output_loss: 2.1808 - val_fine_output_top_5_accuracy: 0.6365 - val_loss: 3.2001 - val_super_output_accuracy: 0.1332 - val_super_output_loss: 1.0191 - learning_rate: 3.0000e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 160ms/step - fine_output_accuracy: 0.4824 - fine_output_loss: 1.4560 - fine_output_top_5_accuracy: 0.7943 - loss: 2.4410 - super_output_accuracy: 0.1546 - super_output_loss: 0.9850 - val_fine_output_accuracy: 0.3366 - val_fine_output_loss: 2.1594 - val_fine_output_top_5_accuracy: 0.6456 - val_loss: 3.1749 - val_super_output_accuracy: 0.1348 - val_super_output_loss: 1.0153 - learning_rate: 3.0000e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 150ms/step - fine_output_accuracy: 0.4855 - fine_output_loss: 1.4426 - fine_output_top_5_accuracy: 0.7959 - loss: 2.4216 - super_output_accuracy: 0.1548 - super_output_loss: 0.9790 - val_fine_output_accuracy: 0.3336 - val_fine_output_loss: 2.1462 - val_fine_output_top_5_accuracy: 0.6475 - val_loss: 3.1626 - val_super_output_accuracy: 0.1375 - val_super_output_loss: 1.0162 - learning_rate: 3.0000e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 172ms/step - fine_output_accuracy: 0.4874 - fine_output_loss: 1.4462 - fine_output_top_5_accuracy: 0.7943 - loss: 2.4280 - super_output_accuracy: 0.1516 - super_output_loss: 0.9817 - val_fine_output_accuracy: 0.3295 - val_fine_output_loss: 2.1638 - val_fine_output_top_5_accuracy: 0.6442 - val_loss: 3.1793 - val_super_output_accuracy: 0.1323 - val_super_output_loss: 1.0153 - learning_rate: 3.0000e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 130ms/step - fine_output_accuracy: 0.4951 - fine_output_loss: 1.4343 - fine_output_top_5_accuracy: 0.7938 - loss: 2.4105 - super_output_accuracy: 0.1600 - super_output_loss: 0.9761 - val_fine_output_accuracy: 0.3306 - val_fine_output_loss: 2.1640 - val_fine_output_top_5_accuracy: 0.6417 - val_loss: 3.1810 - val_super_output_accuracy: 0.1381 - val_super_output_loss: 1.0167 - learning_rate: 3.0000e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 105ms/step - fine_output_accuracy: 0.4923 - fine_output_loss: 1.4282 - fine_output_top_5_accuracy: 0.7998 - loss: 2.4083 - super_output_accuracy: 0.1522 - super_output_loss: 0.9800 - val_fine_output_accuracy: 0.3181 - val_fine_output_loss: 2.2141 - val_fine_output_top_5_accuracy: 0.6293 - val_loss: 3.2329 - val_super_output_accuracy: 0.1323 - val_super_output_loss: 1.0188 - learning_rate: 3.0000e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 104ms/step - fine_output_accuracy: 0.4907 - fine_output_loss: 1.4223 - fine_output_top_5_accuracy: 0.7978 - loss: 2.3980 - super_output_accuracy: 0.1559 - super_output_loss: 0.9757 - val_fine_output_accuracy: 0.3514 - val_fine_output_loss: 2.0989 - val_fine_output_top_5_accuracy: 0.6599 - val_loss: 3.1101 - val_super_output_accuracy: 0.1379 - val_super_output_loss: 1.0110 - learning_rate: 3.0000e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 107ms/step - fine_output_accuracy: 0.4979 - fine_output_loss: 1.4140 - fine_output_top_5_accuracy: 0.7999 - loss: 2.3905 - super_output_accuracy: 0.1570 - super_output_loss: 0.9765 - val_fine_output_accuracy: 0.3382 - val_fine_output_loss: 2.1355 - val_fine_output_top_5_accuracy: 0.6501 - val_loss: 3.1500 - val_super_output_accuracy: 0.1361 - val_super_output_loss: 1.0143 - learning_rate: 3.0000e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 104ms/step - fine_output_accuracy: 0.4962 - fine_output_loss: 1.4119 - fine_output_top_5_accuracy: 0.7989 - loss: 2.3894 - super_output_accuracy: 0.1583 - super_output_loss: 0.9775 - val_fine_output_accuracy: 0.3408 - val_fine_output_loss: 2.1380 - val_fine_output_top_5_accuracy: 0.6489 - val_loss: 3.1524 - val_super_output_accuracy: 0.1379 - val_super_output_loss: 1.0141 - learning_rate: 3.0000e-04\n",
            "Epoch 93/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 104ms/step - fine_output_accuracy: 0.4949 - fine_output_loss: 1.4141 - fine_output_top_5_accuracy: 0.8019 - loss: 2.3935 - super_output_accuracy: 0.1556 - super_output_loss: 0.9795 - val_fine_output_accuracy: 0.3150 - val_fine_output_loss: 2.2013 - val_fine_output_top_5_accuracy: 0.6336 - val_loss: 3.2192 - val_super_output_accuracy: 0.1345 - val_super_output_loss: 1.0179 - learning_rate: 3.0000e-04\n",
            "Epoch 94/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 116ms/step - fine_output_accuracy: 0.4912 - fine_output_loss: 1.4256 - fine_output_top_5_accuracy: 0.8004 - loss: 2.4031 - super_output_accuracy: 0.1572 - super_output_loss: 0.9774 - val_fine_output_accuracy: 0.3383 - val_fine_output_loss: 2.1539 - val_fine_output_top_5_accuracy: 0.6466 - val_loss: 3.1685 - val_super_output_accuracy: 0.1357 - val_super_output_loss: 1.0144 - learning_rate: 3.0000e-04\n",
            "Epoch 95/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 141ms/step - fine_output_accuracy: 0.4995 - fine_output_loss: 1.3976 - fine_output_top_5_accuracy: 0.8069 - loss: 2.3720 - super_output_accuracy: 0.1617 - super_output_loss: 0.9744 - val_fine_output_accuracy: 0.3429 - val_fine_output_loss: 2.1417 - val_fine_output_top_5_accuracy: 0.6494 - val_loss: 3.1579 - val_super_output_accuracy: 0.1334 - val_super_output_loss: 1.0161 - learning_rate: 3.0000e-04\n",
            "Epoch 96/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 147ms/step - fine_output_accuracy: 0.4905 - fine_output_loss: 1.4290 - fine_output_top_5_accuracy: 0.7970 - loss: 2.4047 - super_output_accuracy: 0.1580 - super_output_loss: 0.9757 - val_fine_output_accuracy: 0.3285 - val_fine_output_loss: 2.1810 - val_fine_output_top_5_accuracy: 0.6421 - val_loss: 3.1985 - val_super_output_accuracy: 0.1324 - val_super_output_loss: 1.0175 - learning_rate: 3.0000e-04\n",
            "Epoch 97/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 109ms/step - fine_output_accuracy: 0.4984 - fine_output_loss: 1.4066 - fine_output_top_5_accuracy: 0.8028 - loss: 2.3822 - super_output_accuracy: 0.1586 - super_output_loss: 0.9756 - val_fine_output_accuracy: 0.3496 - val_fine_output_loss: 2.1015 - val_fine_output_top_5_accuracy: 0.6615 - val_loss: 3.1128 - val_super_output_accuracy: 0.1403 - val_super_output_loss: 1.0111 - learning_rate: 3.0000e-04\n",
            "Epoch 98/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 106ms/step - fine_output_accuracy: 0.5034 - fine_output_loss: 1.3967 - fine_output_top_5_accuracy: 0.8031 - loss: 2.3694 - super_output_accuracy: 0.1612 - super_output_loss: 0.9727 - val_fine_output_accuracy: 0.3381 - val_fine_output_loss: 2.1377 - val_fine_output_top_5_accuracy: 0.6493 - val_loss: 3.1518 - val_super_output_accuracy: 0.1383 - val_super_output_loss: 1.0137 - learning_rate: 3.0000e-04\n",
            "Epoch 99/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 107ms/step - fine_output_accuracy: 0.4953 - fine_output_loss: 1.4051 - fine_output_top_5_accuracy: 0.8069 - loss: 2.3778 - super_output_accuracy: 0.1642 - super_output_loss: 0.9727 - val_fine_output_accuracy: 0.3555 - val_fine_output_loss: 2.0687 - val_fine_output_top_5_accuracy: 0.6712 - val_loss: 3.0769 - val_super_output_accuracy: 0.1424 - val_super_output_loss: 1.0079 - learning_rate: 3.0000e-04\n",
            "Epoch 100/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 107ms/step - fine_output_accuracy: 0.4979 - fine_output_loss: 1.4080 - fine_output_top_5_accuracy: 0.8033 - loss: 2.3828 - super_output_accuracy: 0.1598 - super_output_loss: 0.9749 - val_fine_output_accuracy: 0.3274 - val_fine_output_loss: 2.1722 - val_fine_output_top_5_accuracy: 0.6433 - val_loss: 3.1885 - val_super_output_accuracy: 0.1348 - val_super_output_loss: 1.0161 - learning_rate: 3.0000e-04\n",
            "Epoch 101/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 112ms/step - fine_output_accuracy: 0.5063 - fine_output_loss: 1.3824 - fine_output_top_5_accuracy: 0.8098 - loss: 2.3583 - super_output_accuracy: 0.1596 - super_output_loss: 0.9758 - val_fine_output_accuracy: 0.3173 - val_fine_output_loss: 2.1995 - val_fine_output_top_5_accuracy: 0.6329 - val_loss: 3.2161 - val_super_output_accuracy: 0.1313 - val_super_output_loss: 1.0164 - learning_rate: 3.0000e-04\n",
            "Epoch 102/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 111ms/step - fine_output_accuracy: 0.5084 - fine_output_loss: 1.3774 - fine_output_top_5_accuracy: 0.8078 - loss: 2.3517 - super_output_accuracy: 0.1586 - super_output_loss: 0.9743 - val_fine_output_accuracy: 0.3442 - val_fine_output_loss: 2.1181 - val_fine_output_top_5_accuracy: 0.6555 - val_loss: 3.1292 - val_super_output_accuracy: 0.1430 - val_super_output_loss: 1.0109 - learning_rate: 3.0000e-04\n",
            "Epoch 103/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 110ms/step - fine_output_accuracy: 0.5053 - fine_output_loss: 1.3913 - fine_output_top_5_accuracy: 0.8037 - loss: 2.3648 - super_output_accuracy: 0.1573 - super_output_loss: 0.9734 - val_fine_output_accuracy: 0.3409 - val_fine_output_loss: 2.1538 - val_fine_output_top_5_accuracy: 0.6492 - val_loss: 3.1680 - val_super_output_accuracy: 0.1363 - val_super_output_loss: 1.0141 - learning_rate: 3.0000e-04\n",
            "Epoch 104/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 112ms/step - fine_output_accuracy: 0.5085 - fine_output_loss: 1.3772 - fine_output_top_5_accuracy: 0.8103 - loss: 2.3511 - super_output_accuracy: 0.1578 - super_output_loss: 0.9740 - val_fine_output_accuracy: 0.3309 - val_fine_output_loss: 2.1683 - val_fine_output_top_5_accuracy: 0.6464 - val_loss: 3.1840 - val_super_output_accuracy: 0.1361 - val_super_output_loss: 1.0154 - learning_rate: 3.0000e-04\n",
            "Epoch 105/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 112ms/step - fine_output_accuracy: 0.5026 - fine_output_loss: 1.3829 - fine_output_top_5_accuracy: 0.8073 - loss: 2.3566 - super_output_accuracy: 0.1562 - super_output_loss: 0.9737 - val_fine_output_accuracy: 0.3277 - val_fine_output_loss: 2.1664 - val_fine_output_top_5_accuracy: 0.6458 - val_loss: 3.1820 - val_super_output_accuracy: 0.1324 - val_super_output_loss: 1.0154 - learning_rate: 3.0000e-04\n",
            "Epoch 106/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 116ms/step - fine_output_accuracy: 0.4990 - fine_output_loss: 1.3950 - fine_output_top_5_accuracy: 0.8073 - loss: 2.3670 - super_output_accuracy: 0.1591 - super_output_loss: 0.9720 - val_fine_output_accuracy: 0.3443 - val_fine_output_loss: 2.1250 - val_fine_output_top_5_accuracy: 0.6577 - val_loss: 3.1365 - val_super_output_accuracy: 0.1383 - val_super_output_loss: 1.0112 - learning_rate: 3.0000e-04\n",
            "Epoch 107/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 121ms/step - fine_output_accuracy: 0.5082 - fine_output_loss: 1.3725 - fine_output_top_5_accuracy: 0.8111 - loss: 2.3429 - super_output_accuracy: 0.1671 - super_output_loss: 0.9704 - val_fine_output_accuracy: 0.3172 - val_fine_output_loss: 2.2174 - val_fine_output_top_5_accuracy: 0.6312 - val_loss: 3.2332 - val_super_output_accuracy: 0.1379 - val_super_output_loss: 1.0157 - learning_rate: 3.0000e-04\n",
            "Epoch 108/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 160ms/step - fine_output_accuracy: 0.5165 - fine_output_loss: 1.3560 - fine_output_top_5_accuracy: 0.8133 - loss: 2.3264 - super_output_accuracy: 0.1621 - super_output_loss: 0.9704 - val_fine_output_accuracy: 0.3439 - val_fine_output_loss: 2.1243 - val_fine_output_top_5_accuracy: 0.6507 - val_loss: 3.1341 - val_super_output_accuracy: 0.1422 - val_super_output_loss: 1.0097 - learning_rate: 3.0000e-04\n",
            "Epoch 109/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - fine_output_accuracy: 0.5053 - fine_output_loss: 1.3770 - fine_output_top_5_accuracy: 0.8095 - loss: 2.3490 - super_output_accuracy: 0.1597 - super_output_loss: 0.9720\n",
            "Epoch 109: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 123ms/step - fine_output_accuracy: 0.5053 - fine_output_loss: 1.3770 - fine_output_top_5_accuracy: 0.8095 - loss: 2.3490 - super_output_accuracy: 0.1597 - super_output_loss: 0.9720 - val_fine_output_accuracy: 0.3474 - val_fine_output_loss: 2.1032 - val_fine_output_top_5_accuracy: 0.6561 - val_loss: 3.1122 - val_super_output_accuracy: 0.1410 - val_super_output_loss: 1.0087 - learning_rate: 3.0000e-04\n",
            "Epoch 110/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 120ms/step - fine_output_accuracy: 0.5137 - fine_output_loss: 1.3505 - fine_output_top_5_accuracy: 0.8155 - loss: 2.3203 - super_output_accuracy: 0.1638 - super_output_loss: 0.9698 - val_fine_output_accuracy: 0.3578 - val_fine_output_loss: 2.0741 - val_fine_output_top_5_accuracy: 0.6651 - val_loss: 3.0809 - val_super_output_accuracy: 0.1412 - val_super_output_loss: 1.0066 - learning_rate: 9.0000e-05\n",
            "Epoch 111/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 113ms/step - fine_output_accuracy: 0.5190 - fine_output_loss: 1.3412 - fine_output_top_5_accuracy: 0.8180 - loss: 2.3064 - super_output_accuracy: 0.1672 - super_output_loss: 0.9652 - val_fine_output_accuracy: 0.3601 - val_fine_output_loss: 2.0682 - val_fine_output_top_5_accuracy: 0.6680 - val_loss: 3.0756 - val_super_output_accuracy: 0.1400 - val_super_output_loss: 1.0071 - learning_rate: 9.0000e-05\n",
            "Epoch 112/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 112ms/step - fine_output_accuracy: 0.5224 - fine_output_loss: 1.3286 - fine_output_top_5_accuracy: 0.8170 - loss: 2.2947 - super_output_accuracy: 0.1648 - super_output_loss: 0.9661 - val_fine_output_accuracy: 0.3591 - val_fine_output_loss: 2.0784 - val_fine_output_top_5_accuracy: 0.6678 - val_loss: 3.0858 - val_super_output_accuracy: 0.1420 - val_super_output_loss: 1.0071 - learning_rate: 9.0000e-05\n",
            "Epoch 113/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 113ms/step - fine_output_accuracy: 0.5221 - fine_output_loss: 1.3292 - fine_output_top_5_accuracy: 0.8222 - loss: 2.3001 - super_output_accuracy: 0.1609 - super_output_loss: 0.9709 - val_fine_output_accuracy: 0.3583 - val_fine_output_loss: 2.0628 - val_fine_output_top_5_accuracy: 0.6698 - val_loss: 3.0681 - val_super_output_accuracy: 0.1426 - val_super_output_loss: 1.0051 - learning_rate: 9.0000e-05\n",
            "Epoch 114/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 114ms/step - fine_output_accuracy: 0.5208 - fine_output_loss: 1.3369 - fine_output_top_5_accuracy: 0.8163 - loss: 2.3061 - super_output_accuracy: 0.1601 - super_output_loss: 0.9691 - val_fine_output_accuracy: 0.3489 - val_fine_output_loss: 2.0940 - val_fine_output_top_5_accuracy: 0.6617 - val_loss: 3.1024 - val_super_output_accuracy: 0.1420 - val_super_output_loss: 1.0082 - learning_rate: 9.0000e-05\n",
            "Epoch 115/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 114ms/step - fine_output_accuracy: 0.5179 - fine_output_loss: 1.3312 - fine_output_top_5_accuracy: 0.8166 - loss: 2.2998 - super_output_accuracy: 0.1626 - super_output_loss: 0.9685 - val_fine_output_accuracy: 0.3571 - val_fine_output_loss: 2.0715 - val_fine_output_top_5_accuracy: 0.6698 - val_loss: 3.0786 - val_super_output_accuracy: 0.1422 - val_super_output_loss: 1.0068 - learning_rate: 9.0000e-05\n",
            "Epoch 116/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 112ms/step - fine_output_accuracy: 0.5189 - fine_output_loss: 1.3349 - fine_output_top_5_accuracy: 0.8164 - loss: 2.3041 - super_output_accuracy: 0.1632 - super_output_loss: 0.9692 - val_fine_output_accuracy: 0.3565 - val_fine_output_loss: 2.0786 - val_fine_output_top_5_accuracy: 0.6671 - val_loss: 3.0861 - val_super_output_accuracy: 0.1401 - val_super_output_loss: 1.0074 - learning_rate: 9.0000e-05\n",
            "Epoch 117/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 103ms/step - fine_output_accuracy: 0.5251 - fine_output_loss: 1.3349 - fine_output_top_5_accuracy: 0.8169 - loss: 2.3023 - super_output_accuracy: 0.1636 - super_output_loss: 0.9675 - val_fine_output_accuracy: 0.3713 - val_fine_output_loss: 2.0346 - val_fine_output_top_5_accuracy: 0.6769 - val_loss: 3.0392 - val_super_output_accuracy: 0.1432 - val_super_output_loss: 1.0043 - learning_rate: 9.0000e-05\n",
            "Epoch 118/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 104ms/step - fine_output_accuracy: 0.5238 - fine_output_loss: 1.3350 - fine_output_top_5_accuracy: 0.8167 - loss: 2.3049 - super_output_accuracy: 0.1622 - super_output_loss: 0.9699 - val_fine_output_accuracy: 0.3484 - val_fine_output_loss: 2.0988 - val_fine_output_top_5_accuracy: 0.6616 - val_loss: 3.1086 - val_super_output_accuracy: 0.1393 - val_super_output_loss: 1.0097 - learning_rate: 9.0000e-05\n",
            "Epoch 119/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 105ms/step - fine_output_accuracy: 0.5282 - fine_output_loss: 1.3338 - fine_output_top_5_accuracy: 0.8142 - loss: 2.2996 - super_output_accuracy: 0.1650 - super_output_loss: 0.9658 - val_fine_output_accuracy: 0.3517 - val_fine_output_loss: 2.0883 - val_fine_output_top_5_accuracy: 0.6654 - val_loss: 3.0959 - val_super_output_accuracy: 0.1417 - val_super_output_loss: 1.0074 - learning_rate: 9.0000e-05\n",
            "Epoch 120/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 105ms/step - fine_output_accuracy: 0.5232 - fine_output_loss: 1.3301 - fine_output_top_5_accuracy: 0.8196 - loss: 2.2959 - super_output_accuracy: 0.1647 - super_output_loss: 0.9658 - val_fine_output_accuracy: 0.3461 - val_fine_output_loss: 2.1025 - val_fine_output_top_5_accuracy: 0.6637 - val_loss: 3.1116 - val_super_output_accuracy: 0.1413 - val_super_output_loss: 1.0090 - learning_rate: 9.0000e-05\n",
            "Epoch 121/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 105ms/step - fine_output_accuracy: 0.5250 - fine_output_loss: 1.3235 - fine_output_top_5_accuracy: 0.8181 - loss: 2.2910 - super_output_accuracy: 0.1623 - super_output_loss: 0.9674 - val_fine_output_accuracy: 0.3531 - val_fine_output_loss: 2.0876 - val_fine_output_top_5_accuracy: 0.6644 - val_loss: 3.0956 - val_super_output_accuracy: 0.1393 - val_super_output_loss: 1.0078 - learning_rate: 9.0000e-05\n",
            "Epoch 122/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 105ms/step - fine_output_accuracy: 0.5249 - fine_output_loss: 1.3231 - fine_output_top_5_accuracy: 0.8211 - loss: 2.2898 - super_output_accuracy: 0.1634 - super_output_loss: 0.9666 - val_fine_output_accuracy: 0.3536 - val_fine_output_loss: 2.0957 - val_fine_output_top_5_accuracy: 0.6642 - val_loss: 3.1032 - val_super_output_accuracy: 0.1392 - val_super_output_loss: 1.0074 - learning_rate: 9.0000e-05\n",
            "Epoch 123/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 106ms/step - fine_output_accuracy: 0.5215 - fine_output_loss: 1.3240 - fine_output_top_5_accuracy: 0.8211 - loss: 2.2910 - super_output_accuracy: 0.1651 - super_output_loss: 0.9671 - val_fine_output_accuracy: 0.3554 - val_fine_output_loss: 2.0867 - val_fine_output_top_5_accuracy: 0.6670 - val_loss: 3.0933 - val_super_output_accuracy: 0.1430 - val_super_output_loss: 1.0065 - learning_rate: 9.0000e-05\n",
            "Epoch 124/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 106ms/step - fine_output_accuracy: 0.5263 - fine_output_loss: 1.3145 - fine_output_top_5_accuracy: 0.8225 - loss: 2.2775 - super_output_accuracy: 0.1632 - super_output_loss: 0.9629 - val_fine_output_accuracy: 0.3533 - val_fine_output_loss: 2.0857 - val_fine_output_top_5_accuracy: 0.6655 - val_loss: 3.0929 - val_super_output_accuracy: 0.1415 - val_super_output_loss: 1.0070 - learning_rate: 9.0000e-05\n",
            "Epoch 125/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 109ms/step - fine_output_accuracy: 0.5253 - fine_output_loss: 1.3083 - fine_output_top_5_accuracy: 0.8234 - loss: 2.2747 - super_output_accuracy: 0.1614 - super_output_loss: 0.9665 - val_fine_output_accuracy: 0.3587 - val_fine_output_loss: 2.0814 - val_fine_output_top_5_accuracy: 0.6667 - val_loss: 3.0872 - val_super_output_accuracy: 0.1448 - val_super_output_loss: 1.0056 - learning_rate: 9.0000e-05\n",
            "Epoch 126/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 109ms/step - fine_output_accuracy: 0.5227 - fine_output_loss: 1.3305 - fine_output_top_5_accuracy: 0.8208 - loss: 2.2948 - super_output_accuracy: 0.1637 - super_output_loss: 0.9643 - val_fine_output_accuracy: 0.3555 - val_fine_output_loss: 2.0865 - val_fine_output_top_5_accuracy: 0.6661 - val_loss: 3.0923 - val_super_output_accuracy: 0.1428 - val_super_output_loss: 1.0056 - learning_rate: 9.0000e-05\n",
            "Epoch 127/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - fine_output_accuracy: 0.5277 - fine_output_loss: 1.3146 - fine_output_top_5_accuracy: 0.8221 - loss: 2.2808 - super_output_accuracy: 0.1664 - super_output_loss: 0.9662\n",
            "Epoch 127: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 193ms/step - fine_output_accuracy: 0.5277 - fine_output_loss: 1.3146 - fine_output_top_5_accuracy: 0.8221 - loss: 2.2808 - super_output_accuracy: 0.1664 - super_output_loss: 0.9662 - val_fine_output_accuracy: 0.3632 - val_fine_output_loss: 2.0654 - val_fine_output_top_5_accuracy: 0.6763 - val_loss: 3.0707 - val_super_output_accuracy: 0.1405 - val_super_output_loss: 1.0051 - learning_rate: 9.0000e-05\n",
            "Epoch 128/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 223ms/step - fine_output_accuracy: 0.5300 - fine_output_loss: 1.3012 - fine_output_top_5_accuracy: 0.8228 - loss: 2.2647 - super_output_accuracy: 0.1639 - super_output_loss: 0.9635 - val_fine_output_accuracy: 0.3619 - val_fine_output_loss: 2.0648 - val_fine_output_top_5_accuracy: 0.6718 - val_loss: 3.0702 - val_super_output_accuracy: 0.1427 - val_super_output_loss: 1.0051 - learning_rate: 2.7000e-05\n",
            "Epoch 129/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 196ms/step - fine_output_accuracy: 0.5311 - fine_output_loss: 1.3131 - fine_output_top_5_accuracy: 0.8207 - loss: 2.2797 - super_output_accuracy: 0.1640 - super_output_loss: 0.9666 - val_fine_output_accuracy: 0.3589 - val_fine_output_loss: 2.0750 - val_fine_output_top_5_accuracy: 0.6714 - val_loss: 3.0813 - val_super_output_accuracy: 0.1417 - val_super_output_loss: 1.0061 - learning_rate: 2.7000e-05\n",
            "Epoch 130/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 198ms/step - fine_output_accuracy: 0.5271 - fine_output_loss: 1.3079 - fine_output_top_5_accuracy: 0.8247 - loss: 2.2693 - super_output_accuracy: 0.1649 - super_output_loss: 0.9614 - val_fine_output_accuracy: 0.3604 - val_fine_output_loss: 2.0694 - val_fine_output_top_5_accuracy: 0.6723 - val_loss: 3.0754 - val_super_output_accuracy: 0.1420 - val_super_output_loss: 1.0057 - learning_rate: 2.7000e-05\n",
            "Epoch 131/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 198ms/step - fine_output_accuracy: 0.5297 - fine_output_loss: 1.3008 - fine_output_top_5_accuracy: 0.8269 - loss: 2.2628 - super_output_accuracy: 0.1681 - super_output_loss: 0.9620 - val_fine_output_accuracy: 0.3649 - val_fine_output_loss: 2.0607 - val_fine_output_top_5_accuracy: 0.6746 - val_loss: 3.0658 - val_super_output_accuracy: 0.1422 - val_super_output_loss: 1.0049 - learning_rate: 2.7000e-05\n",
            "Epoch 132/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 206ms/step - fine_output_accuracy: 0.5293 - fine_output_loss: 1.3092 - fine_output_top_5_accuracy: 0.8252 - loss: 2.2755 - super_output_accuracy: 0.1618 - super_output_loss: 0.9664 - val_fine_output_accuracy: 0.3586 - val_fine_output_loss: 2.0693 - val_fine_output_top_5_accuracy: 0.6714 - val_loss: 3.0754 - val_super_output_accuracy: 0.1413 - val_super_output_loss: 1.0059 - learning_rate: 2.7000e-05\n",
            "Epoch 133/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 268ms/step - fine_output_accuracy: 0.5273 - fine_output_loss: 1.3026 - fine_output_top_5_accuracy: 0.8263 - loss: 2.2646 - super_output_accuracy: 0.1701 - super_output_loss: 0.9620 - val_fine_output_accuracy: 0.3590 - val_fine_output_loss: 2.0729 - val_fine_output_top_5_accuracy: 0.6710 - val_loss: 3.0783 - val_super_output_accuracy: 0.1423 - val_super_output_loss: 1.0051 - learning_rate: 2.7000e-05\n",
            "Epoch 134/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 274ms/step - fine_output_accuracy: 0.5251 - fine_output_loss: 1.3055 - fine_output_top_5_accuracy: 0.8261 - loss: 2.2696 - super_output_accuracy: 0.1674 - super_output_loss: 0.9641 - val_fine_output_accuracy: 0.3609 - val_fine_output_loss: 2.0658 - val_fine_output_top_5_accuracy: 0.6730 - val_loss: 3.0713 - val_super_output_accuracy: 0.1431 - val_super_output_loss: 1.0053 - learning_rate: 2.7000e-05\n",
            "Epoch 135/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 237ms/step - fine_output_accuracy: 0.5249 - fine_output_loss: 1.3180 - fine_output_top_5_accuracy: 0.8245 - loss: 2.2808 - super_output_accuracy: 0.1633 - super_output_loss: 0.9628 - val_fine_output_accuracy: 0.3685 - val_fine_output_loss: 2.0408 - val_fine_output_top_5_accuracy: 0.6789 - val_loss: 3.0441 - val_super_output_accuracy: 0.1450 - val_super_output_loss: 1.0030 - learning_rate: 2.7000e-05\n",
            "Epoch 136/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 218ms/step - fine_output_accuracy: 0.5323 - fine_output_loss: 1.2899 - fine_output_top_5_accuracy: 0.8269 - loss: 2.2566 - super_output_accuracy: 0.1654 - super_output_loss: 0.9668 - val_fine_output_accuracy: 0.3623 - val_fine_output_loss: 2.0650 - val_fine_output_top_5_accuracy: 0.6726 - val_loss: 3.0692 - val_super_output_accuracy: 0.1421 - val_super_output_loss: 1.0040 - learning_rate: 2.7000e-05\n",
            "Epoch 137/200\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - fine_output_accuracy: 0.5266 - fine_output_loss: 1.3049 - fine_output_top_5_accuracy: 0.8253 - loss: 2.2656 - super_output_accuracy: 0.1696 - super_output_loss: 0.9607\n",
            "Epoch 137: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "\u001b[1m1111/1111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 242ms/step - fine_output_accuracy: 0.5266 - fine_output_loss: 1.3049 - fine_output_top_5_accuracy: 0.8253 - loss: 2.2656 - super_output_accuracy: 0.1696 - super_output_loss: 0.9608 - val_fine_output_accuracy: 0.3596 - val_fine_output_loss: 2.0689 - val_fine_output_top_5_accuracy: 0.6719 - val_loss: 3.0743 - val_super_output_accuracy: 0.1423 - val_super_output_loss: 1.0052 - learning_rate: 2.7000e-05\n",
            "Epoch 137: early stopping\n",
            "Restoring model weights from the end of the best epoch: 117.\n",
            "\n",
            "=== FINAL EVALUATION ===\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - fine_output_accuracy: 0.3696 - fine_output_loss: 2.0626 - fine_output_top_5_accuracy: 0.6709 - loss: 3.0638 - super_output_accuracy: 0.1466 - super_output_loss: 1.0012\n",
            "\n",
            "=== RESULTS SUMMARY ===\n",
            "loss: 3.0392\n",
            "compile_metrics: 1.0043\n",
            "super_output_loss: 2.0346\n",
            "fine_output_loss: 0.3713\n",
            "✓ Model saved as 'improved_hierarchical_model.keras'\n",
            "✓ Class mapping saved\n",
            "\n",
            "=== EXAMPLE PREDICTIONS ===\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Sample 1:\n",
            "  Super class: 27 (confidence: 0.130)\n",
            "  Fine class: 796 (confidence: 0.896)\n",
            "  True label: 796\n",
            "Sample 2:\n",
            "  Super class: 30 (confidence: 0.120)\n",
            "  Fine class: 1839 (confidence: 0.398)\n",
            "  True label: 1839\n",
            "Sample 3:\n",
            "  Super class: 32 (confidence: 0.186)\n",
            "  Fine class: 1288 (confidence: 0.541)\n",
            "  True label: 354\n",
            "Sample 4:\n",
            "  Super class: 25 (confidence: 0.130)\n",
            "  Fine class: 600 (confidence: 0.494)\n",
            "  True label: 583\n",
            "Sample 5:\n",
            "  Super class: 12 (confidence: 0.097)\n",
            "  Fine class: 518 (confidence: 0.332)\n",
            "  True label: 1167\n"
          ]
        }
      ],
      "source": [
        "model, history = run_hierarchical_classification(X_train, y_train, X_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Real-time Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import tensorflow as tf\n",
        "import json\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_PATH = 'hierarchical_model.keras'\n",
        "model = tf.keras.models.load_model(MODEL_PATH)\n",
        "\n",
        "LABEL_MAP_PATH = 'data/processed_data/label_map_full.json'\n",
        "with open(LABEL_MAP_PATH, 'r') as f:\n",
        "    label_map = json.load(f)  \n",
        "    \n",
        "reverse_mapping = {v: k for k, v in label_map.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "mp_hands = mp.solutions.hands\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "hands = mp_hands.Hands(static_image_mode=False, \n",
        "                       max_num_hands=2, \n",
        "                       min_detection_confidence=0.5,\n",
        "                       min_tracking_confidence=0.5)\n",
        "\n",
        "def extract_landmarks(frame):\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    results = hands.process(rgb_frame)\n",
        "    \n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                frame,\n",
        "                hand_landmarks,\n",
        "                mp_hands.HAND_CONNECTIONS\n",
        "            )\n",
        "\n",
        "    landmarks = []\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            for lm in hand_landmarks.landmark:\n",
        "                landmarks.extend([lm.x, lm.y, lm.z])\n",
        "    \n",
        "    while len(landmarks) < 21 * 3 * 2:  # Max 2 hands\n",
        "        landmarks.append(0.0)\n",
        "    \n",
        "    return landmarks[:21 * 3 * 2]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def realtime_detection():\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open webcam.\")\n",
        "        return\n",
        "    \n",
        "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
        "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
        "    \n",
        "    sequence_length = 30  \n",
        "    landmarks_buffer = deque(maxlen=sequence_length)\n",
        "    \n",
        "    prediction_frequency = 10 \n",
        "    frame_counter = 0\n",
        "    current_prediction = \"No prediction yet\"\n",
        "    confidence = 0.0\n",
        "    \n",
        "    print(\"Starting webcam detection. Press 'q' in the OpenCV window to quit.\")\n",
        "    \n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"Error: Could not read frame.\")\n",
        "                break\n",
        "            \n",
        "            frame = cv2.flip(frame, 1)\n",
        "            \n",
        "            landmarks = extract_landmarks(frame)\n",
        "            landmarks_buffer.append(landmarks)\n",
        "            \n",
        "            frame_counter += 1\n",
        "            \n",
        "            if frame_counter >= prediction_frequency and len(landmarks_buffer) == sequence_length:\n",
        "                input_sequence = np.array([list(landmarks_buffer)])\n",
        "                \n",
        "                super_output, fine_output = model.predict(input_sequence, verbose=0)\n",
        "         \n",
        "                fine_prediction = fine_output[0]  \n",
        "                \n",
        "                predicted_class_id = np.argmax(fine_prediction)\n",
        "                confidence = fine_prediction[predicted_class_id] * 100\n",
        "\n",
        "                if predicted_class_id in reverse_mapping and confidence > 50:\n",
        "                    current_prediction = reverse_mapping[predicted_class_id]\n",
        "                else:\n",
        "                    current_prediction = \"Unknown sign\"\n",
        "                \n",
        "                frame_counter = 0\n",
        "\n",
        "            # Show prediction on screen\n",
        "            text = f\"{current_prediction} ({confidence:.1f}%)\"\n",
        "            cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
        "            cv2.putText(frame, \"Press 'q' to quit\", (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "            cv2.imshow('Sign Language Detection', frame)\n",
        "\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "    \n",
        "    finally:\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        print(\"Webcam detection stopped.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting webcam detection. Press 'q' in the OpenCV window to quit.\n",
            "Webcam detection stopped.\n"
          ]
        }
      ],
      "source": [
        "realtime_detection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "B2vsTy0iSs4n",
        "S5mNukEBUexq",
        "1Ty29e7QgLXa",
        "TboyXNdaqBXa"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "numpy_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
